# Default values for lomas_server.

# General stuff
nameOverride: ""
fullnameOverride: "lomas"

# MongoDB 
##########################################################################
mongodb:
  resources: {}
  fullnameOverride: "lomas-mongodb"
  max_pool_size: 100
  min_pool_size: 2
  max_connecting: 2
  architecture: standalone
  image:
    tag: "6.0.9-debian-11-r5"
  auth:
    enabled: true
    rootUser: root
    rootPassword: root_pwd # changeme
    usernames: [user] 
    passwords: [user_pwd] # changeme
    databases: [defaultdb]
  replicaCount: 1
  discoverable:
    allow: true
  security:
    networkPolicy: 
      enabled: true
  persistence:
    # Set this to "keep" to disable data pvc deletion when uninstalling the chart.
    # Subsequent installs will use the same pvc, restoring the state of the server.
    # Note: if the runtime_args.settings.develop_mode is set to True, the server
    # state will be reset (default datasets and budgets).
    resourcePolicy: ""


# Dashboard Fast-API server
##########################################################################
server:  
  image:
    repository: dsccadminch/lomas_server
    pullPolicy: Always
    tag: latest
  imagePullSecrets: []

  # Runtime args for server
  runtime_args:
    settings:
      develop_mode: True # !! Set this to false in production mode !!
      submit_limit: 300
      server:
        host_ip: "0.0.0.0"
        host_port: "8080"     
        log_level: "info"
        reload: True
        workers: 1 # Will be overwritten to one anyway for now.
        time_attack:
          method: "jitter" # or "stall"
          magnitude: 1
      dp_libraries:
        opendp:
          contrib: True
          floating_point: True
          honest_but_curious: True
      private_db_credentials: [] # list of credentials, eg. {credentials_name: "abc", db_type: "S3_DB", ...}


  service:
    type: ClusterIP
    port: 80

  ingress:
    enabled: true
    className: "nginx"
    annotations: 
      nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    hostname: "lomas-server.example.com"
  # Lomas server not meant to be replicated for now
  replicaCount: 1
  # Lomas server not intended to be autoscaled for now
  # autoscaling:
  #  enabled: false
  #  minReplicas: 1
  #  maxReplicas: 100
  #  targetCPUUtilizationPercentage: 80
  #  # targetMemoryUtilizationPercentage: 80

  # We leave unset stuff here
  serviceAccount:
    create: false
    annotations: {}
    name: ""
  resources: {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  podAnnotations: {}
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000
  nodeSelector: {}
  tolerations: []
  affinity: {}

# Lomas Administration Dashboard
##########################################################################
dashboard:
  create: true

  image:
    repository: dsccadminch/lomas_admin_dashboard
    pullPolicy: Always
    tag: latest
  imagePullSecrets: []

  # Runtime args for server
  serverConfig:
    address: "0.0.0.0"
    port: "8501"

  service:
    type: ClusterIP
    port: 80
 
  ingress:
    enabled: true
    className: "nginx"
    annotations: 
      nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    hostname: "lomas-admin-dashboard.example.com"
  # Lomas dashboard not meant to be replicated for now
  replicaCount: 1
  # Lomas dashboard not intended to be autoscaled for now
  # autoscaling:
  #  enabled: false
  #  minReplicas: 1
  #  maxReplicas: 100
  #  targetCPUUtilizationPercentage: 80
  #  # targetMemoryUtilizationPercentage: 80
  
  # We leave unset stuff here
  serviceAccount:
    create: false
    annotations: {}
    name: ""
  resources: {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  podAnnotations: {}
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000
  nodeSelector: {}
  tolerations: []
  affinity: {}

# Opentelemetry-collector
##########################################################################
opentelemetry-collector:
  service:
    enabled: true
    type: ClusterIP

  fullnameOverride: "lomas-otel-collector"
  mode: deployment

  image:
    repository: otel/opentelemetry-collector

  command:
    name: otelcol

  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318

    processors:
      batch:
        timeout: 5s

    exporters:
      debug:
        verbosity: detailed

      otlp/tempo:
        endpoint: http://tempo:4317
        tls:
          insecure: true

      prometheus:
        endpoint: "0.0.0.0:9090"
        namespace: lomas_server

      otlphttp/loki:
        endpoint: http://loki:3100/otlp
        tls:
          insecure: true

    extensions:
      health_check:
        endpoint: "0.0.0.0:13133"
      pprof:
        endpoint: "0.0.0.0:1777"
      zpages:
        endpoint: "0.0.0.0:55679"

    service:
      extensions: [health_check, pprof, zpages]
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch]
          exporters: [debug, otlp/tempo]

        metrics:
          receivers: [otlp]
          processors: [batch]
          exporters: [debug, prometheus]

        logs:
          receivers: [otlp]
          processors: [batch]
          exporters: [debug, otlphttp/loki]


# Grafana
##########################################################################
grafana:
  service:
    type: LoadBalancer

  fullnameOverride: "lomas-grafana-dashboard"

  rbac:
    create: false
    namespaced: true
    extraRoleRules:
    - apiGroups: [""]
      resources: ["pods", "services"]
      verbs: ["get", "watch", "list"]
    extraClusterRoleRules: []

  adminPassword: "admin"
  persistence:
    enabled: true
  datasources: 
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          uid: prometheus
          access: proxy
          orgId: 1
          url: http://prometheus:9090
          basicAuth: false
          isDefault: false
          version: 1
          editable: false
          jsonData:
            httpMethod: GET
        - name: Tempo
          type: tempo
          access: proxy
          orgId: 1
          url: http://tempo:3200
          basicAuth: false
          isDefault: true
          version: 1
          editable: false
          apiVersion: 1
          uid: tempo
          jsonData:
            httpMethod: GET
            serviceMap:
              datasourceUid: prometheus
            streamingEnabled:
              search: true
        - name: Loki
          type: loki
          access: proxy
          url: http://loki:3100
          jsonData:
            httpHeaderName1: "X-Scope-OrgID"
          secureJsonData:
            httpHeaderValue1: "tenant1"
  dashboards:
    default:
      custom-dashboard:
        file: "../../../../configs/observability/grafana/example_dashboard_config.json"
  env:
    GF_SECURITY_ADMIN_USER: admin
    GF_SECURITY_ADMIN_PASSWORD: admin

# Prometheus
##########################################################################
prometheus:
  service:
    type: ClusterIP

  fullnameOverride: "lomas-prometheus"

  kube-state-metrics:
    enabled: false
  
  # prometheus-node-exporter:
  #   enabled: false
  
  # prometheus-pushgateway:
  #   enabled: false

  server:
    name: server
    releaseNamespace: true
    namespaces:
      - user-paulineml

  global:
    scrape_interval: 10s
    evaluation_interval: 10s

  prometheus.yml:
    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      - job_name: 'tempo'
        static_configs:
          - targets: ['tempo:3200']

      - job_name: 'otel-collector'
        static_configs:
          - targets: ['otel-collector:9090']


# Loki
##########################################################################
loki:
  service:
    type: ClusterIP

  fullnameOverride: "lomas-loki"

  rbac:
    create: true
    pspEnabled: false
    namespaced: true 

  monitoring:
    dashboards:
      enabled: false
    selfMonitoring:
      enabled: true
      grafanaAgent:
        installOperator: false
      lokiCanary:
        enabled: false
  auth_enabled: false

  server:
    http_listen_port: 3100

  schema_config:
    configs:
    - from: 2025-01-10
      store: tsdb
      object_store: filesystem
      schema: v13
      index:
        prefix: loki_index_
        period: 24h

  storage:
    type: filesystem
    bucketNames:
      chunks: loki-chunks
      ruler: loki-ruler
      admin: loki-admin
    filesystem:
      chunks_directory: /var/loki/chunks
      rules_directory: /var/loki/rules
      admin_api_directory: /var/loki/admin

# Tempo
##########################################################################
tempo:
  service:
    type: ClusterIP

  fullnameOverride: "lomas-tempo"

  server:
    http_listen_port: 3200

  distributor:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: "tempo:4317"

  ingester:
    max_block_duration: 5m

  metrics_generator:
    registry:
      external_labels:
        source: tempo
    storage:
      path: /var/tempo/generator/wal
      remote_write:
        - url: http://prometheus:9090/api/v1/write
          send_exemplars: true
    traces_storage:
      path: /var/tempo/generator/traces

  persistence:
    enabled: true