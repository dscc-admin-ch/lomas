{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ffd914-9ebf-47ac-ba27-282390de1fc8",
   "metadata": {},
   "source": [
    "# Smartnoise Synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e7614e-3c1c-4a12-b1e0-235e1e42ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lomas_client import Client\n",
    "from snsynth import Synthesizer # Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4407847c-dd68-4655-84a6-8013afd4ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_URL = \"http://lomas_server\"\n",
    "USER_NAME = \"Dr. Antartica\"\n",
    "DATASET_NAME = \"PENGUIN\"\n",
    "client = Client(url=APP_URL, user_name = USER_NAME, dataset_name = DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45a43df-7f54-45d5-bdf9-2e9f3fad4b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_ids': 1,\n",
       " 'row_privacy': True,\n",
       " 'censor_dims': False,\n",
       " 'columns': {'species': {'type': 'string',\n",
       "   'cardinality': 3,\n",
       "   'categories': ['Adelie', 'Chinstrap', 'Gentoo']},\n",
       "  'island': {'type': 'string',\n",
       "   'cardinality': 3,\n",
       "   'categories': ['Torgersen', 'Biscoe', 'Dream']},\n",
       "  'bill_length_mm': {'type': 'float', 'lower': 30.0, 'upper': 65.0},\n",
       "  'bill_depth_mm': {'type': 'float', 'lower': 13.0, 'upper': 23.0},\n",
       "  'flipper_length_mm': {'type': 'float', 'lower': 150.0, 'upper': 250.0},\n",
       "  'body_mass_g': {'type': 'float', 'lower': 2000.0, 'upper': 7000.0},\n",
       "  'sex': {'type': 'string',\n",
       "   'cardinality': 2,\n",
       "   'categories': ['MALE', 'FEMALE']}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguin_metadata = client.get_dataset_metadata()\n",
    "penguin_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09010e63-2a10-4d97-a6bb-8aa9fa1d8709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mwem', 'dpctgan', 'patectgan', 'mst', 'pacsynth', 'dpgan', 'pategan', 'aim']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Synthesizer.list_synthesizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57dfb6ec-1371-41b6-8546-6540ee1e3ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epsilon_cost': 2.0, 'delta_cost': 0.0001}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = client.estimate_smartnoise_synth_cost(\n",
    "    synth_name=\"dpctgan\",\n",
    "    epsilon= 2.0,\n",
    "    delta = 0.0001,\n",
    "    select_cols = [\"bill_length_mm\"],\n",
    "    mul_matrix = [],\n",
    "    synth_params = {},\n",
    "    nullable = True,\n",
    "    table_transformer_style = \"gan\",\n",
    ")\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18db6fa-7160-46f8-b299-68a54448afd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/usr/local/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query_response': <snsynth.pytorch.nn.dpctgan.DPCTGAN at 0x7f3daa605650>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = client.smartnoise_synth_query(\n",
    "    synth_name=\"dpctgan\",\n",
    "    epsilon= 2.0,\n",
    "    delta = 0.0001,\n",
    "    select_cols = [\"bill_length_mm\"],\n",
    "    mul_matrix = [],\n",
    "    synth_params = {\n",
    "        \"embedding_dim\": 128, \n",
    "        \"generator_dim\": (256, 256), \n",
    "        \"discriminator_dim\": (256, 256),\n",
    "        \"batch_size\": 2\n",
    "    },\n",
    "    nullable = True,\n",
    "    table_transformer_style = \"gan\",\n",
    "    dummy = True\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49ce94e8-bfdb-4f3a-9fcc-2c7b2d3f6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = res[\"query_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cac5d5bc-abb6-4d40-a944-eeec22233297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.075561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.046139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.004793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.004920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.006769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bill_length_mm\n",
       "0       30.075561\n",
       "1       30.046139\n",
       "2       30.004793\n",
       "3       30.004920\n",
       "4       30.006769"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0370113-c028-4d06-b3e8-cb68e16cc7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from snsynth import Synthesizer\n",
    "from snsynth.transform import (\n",
    "    AnonymizationTransformer,\n",
    "    BinTransformer,\n",
    "    ChainTransformer,\n",
    "    #DateTimeTransformer,\n",
    "    LabelTransformer,\n",
    "    MinMaxTransformer,\n",
    "    OneHotEncoder,\n",
    ")\n",
    "from snsynth.transform.table import TableTransformer\n",
    "\n",
    "from typing import Dict, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f931338-72ce-45f2-87c6-da95301dbc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Synthesizer.list_synthesizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c76df9-8046-4438-bd66-b18161dc7def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class SmartnoiseSynthModel(BaseModel):\n",
    "    \"\"\"Model input for a smarnoise-synth query\"\"\"\n",
    "\n",
    "    dataset_name: str\n",
    "    synth_name: str\n",
    "    epsilon: float = 0.0\n",
    "    delta: float = 0.0\n",
    "    select_cols: List = []\n",
    "    synth_params: dict = {}\n",
    "    mul_matrix: List = []\n",
    "    nullable: bool = True\n",
    "    condition: Optional[str] = None\n",
    "    nb_samples: Optional[int] = None\n",
    "    table_transformer_style: str = \"gan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627f54e-c652-4b0c-a940-ce980bb12223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import StrEnum\n",
    "class SSynthSynthesizer(StrEnum):\n",
    "    \"\"\"Synthesizer models for smartnoise synth\"\"\"\n",
    "\n",
    "    # Marginal Synthesizer\n",
    "    AIM = \"aim\"\n",
    "    MWEM = \"mwem\"\n",
    "    MST = \"mst\"\n",
    "    PAC_SYNTH = \"pacsynth\"\n",
    "\n",
    "    # Neural Network Synthesizer\n",
    "    DP_CTGAN = \"dpctgan\"\n",
    "    PATE_CTGAN = \"patectgan\"\n",
    "    PATE_GAN = \"pategan\"  # no documentation\n",
    "    DP_GAN = \"dpgan\"  # no documentation\n",
    "\n",
    "    # Hybrid Synthesizer\n",
    "    QUAIL = \"quail\"\n",
    "\n",
    "\n",
    "class SSynthTableTransStyle(StrEnum):\n",
    "    \"\"\"Transformer style for smartnoise synth\"\"\"\n",
    "\n",
    "    GAN = \"gan\"\n",
    "    CUBE = \"cube\"\n",
    "\n",
    "\n",
    "class SSynthColumnType(StrEnum):\n",
    "    \"\"\"Type of columns for SmartnoiseSynth transformer pre-processing\"\"\"\n",
    "\n",
    "    PRIVATE_ID = \"private_id\"\n",
    "    CATEGORICAL = \"categorical\"\n",
    "    CONTINUOUS = \"continuous\"\n",
    "    ORDINAL = \"ordinal\"\n",
    "    DATETIME = \"datetime\"\n",
    "\n",
    "\n",
    "SSYNTH_PRIVATE_COLUMN = \"uuid\"\n",
    "SSYNTH_DEFAULT_NB_SAMPLES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5171177-d04f-4464-897c-4bfefae959ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_data(\n",
    "        private_data: pd.DataFrame,\n",
    "        query_json: dict,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Preprocess the data based on the query parameters.\n",
    "\n",
    "        Args:\n",
    "            private_data (pd.DataFrame): Private data to be preprocessed\n",
    "            query_json (dict): (SmartnoiseSynthModelCost): JSON request object\n",
    "                select_cols (List[str]): List of columns to select\n",
    "                mul_matrix (List): Multiplication matrix for columns aggregations\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Preprocessed private data\n",
    "        \"\"\"\n",
    "        if query_json.select_cols:\n",
    "            try:\n",
    "                private_data = private_data[query_json.select_cols]\n",
    "            except KeyError as e:\n",
    "                raise ValueError(\n",
    "                    \"Error while selecting provided select_cols: \" + str(e)\n",
    "                ) from e\n",
    "\n",
    "        if query_json.mul_matrix:\n",
    "            try:\n",
    "                np_matrix = np.array(query_json.mul_matrix)\n",
    "                mul_private_data = private_data.to_numpy().dot(np_matrix.T)\n",
    "                private_data = pd.DataFrame(mul_private_data)\n",
    "            except ValueError as e:\n",
    "                raise ValueError(\n",
    "                    f\"Failed to multiply provided mul_matrix: {(str(e))}\"\n",
    "                ) from e\n",
    "        return private_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283a54c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _categorize_column(data: dict) -> str:\n",
    "    \"\"\"\n",
    "    Categorize the column based on its metadata.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Metadata of the column.\n",
    "\n",
    "    Returns:\n",
    "        str: Category of the column.\n",
    "    \"\"\"\n",
    "    match data[\"type\"]:\n",
    "        case \"string\" | \"boolean\":\n",
    "            return SSynthColumnType.CATEGORICAL\n",
    "        case \"int\" | \"float\":\n",
    "            if \"lower\" in data.keys():\n",
    "                return SSynthColumnType.CONTINUOUS\n",
    "            if \"cardinality\" in data.keys():\n",
    "                return SSynthColumnType.CATEGORICAL\n",
    "            return SSynthColumnType.ORDINAL\n",
    "        case \"datetime\":\n",
    "            return SSynthColumnType.DATETIME\n",
    "        case _:\n",
    "            raise ValueError(\n",
    "                f\"Unknown column type in metadata: {data['type']}\"\n",
    "            )\n",
    "\n",
    "def _get_column_by_types(\n",
    "    metadata,\n",
    "    select_cols: List[str],\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Sort the column in categories based on their types and metadata\n",
    "\n",
    "    Args:\n",
    "        metadata (Metadata): Metadata of the dataset\n",
    "        select_cols (List[str]): List of columns to select\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[str]]: Dictionnary of list of columns by categories\n",
    "    \"\"\"\n",
    "    col_categories: Dict[str, List[str]] = {\n",
    "        SSynthColumnType.CATEGORICAL: [],\n",
    "        SSynthColumnType.CONTINUOUS: [],\n",
    "        SSynthColumnType.DATETIME: [],\n",
    "        SSynthColumnType.ORDINAL: [],\n",
    "        SSynthColumnType.PRIVATE_ID: [],\n",
    "    }\n",
    "    for col_name, data in metadata[\"columns\"].items():\n",
    "        if select_cols and col_name not in select_cols:\n",
    "            continue\n",
    "        \n",
    "        if \"private_id\" in data.keys():\n",
    "            col_categories[SSynthColumnType.PRIVATE_ID].append(col_name)\n",
    "            continue\n",
    "\n",
    "        # Sort the column in categories based on their types and metadata\n",
    "        category = _categorize_column(data)\n",
    "        col_categories[category].append(col_name)\n",
    "\n",
    "    return col_categories\n",
    "\n",
    "def _prepare_data_transformer(\n",
    "    metadata,\n",
    "    private_data: pd.DataFrame,\n",
    "    query_json: dict,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates the transformer based on the metadata\n",
    "    The transformer is used to transform the data before synthesis and then\n",
    "    reverse the transformation after synthesis.\n",
    "    See https://docs.smartnoise.org/synth/transforms/index.html for documentation\n",
    "    See https://github.com/opendp/smartnoise-sdk/blob/main/synth/snsynth/\n",
    "        transform/type_map.py#L40 for get_transformer() method taken as basis.\n",
    "\n",
    "    Args:\n",
    "        metadata (Metadata): Metadata of the dataset\n",
    "        private_data\n",
    "        query_json (SmartnoiseSynthModelCost): JSON request object for the query\n",
    "            select_cols (List[str]): List of columns to select\n",
    "            nullable (bool): True is the data can have Null values, False otherwise\n",
    "            table_transformer_style: 'gan' or 'cube'\n",
    "\n",
    "    Returns:\n",
    "        table_tranformer (TableTransformer) to pre and post-process the data\n",
    "    \"\"\"\n",
    "    col_categories = _get_column_by_types(metadata, query_json.select_cols)\n",
    "    style = query_json.table_transformer_style\n",
    "    nullable = query_json.nullable\n",
    "\n",
    "    constraints = {}\n",
    "    for col in col_categories[SSynthColumnType.PRIVATE_ID]:\n",
    "        constraints[col] = AnonymizationTransformer(SSYNTH_PRIVATE_COLUMN)\n",
    "\n",
    "    if style == SSynthTableTransStyle.GAN:\n",
    "        for col in col_categories[SSynthColumnType.CATEGORICAL]:\n",
    "            constraints[col] = ChainTransformer(\n",
    "                [LabelTransformer(nullable=nullable), OneHotEncoder()]\n",
    "            )\n",
    "        for col in col_categories[SSynthColumnType.CONTINUOUS]:\n",
    "            constraints[col] = MinMaxTransformer(\n",
    "                lower=metadata[\"columns\"][col][\"lower\"],\n",
    "                upper=metadata[\"columns\"][col][\"upper\"],\n",
    "                nullable=nullable,\n",
    "            )\n",
    "        for col in col_categories[SSynthColumnType.DATETIME]:\n",
    "            constraints[col] = ChainTransformer(\n",
    "                [\n",
    "                    DateTimeTransformer(),\n",
    "                    MinMaxTransformer(\n",
    "                        lower=metadata[\"columns\"][col][\"lower\"],\n",
    "                        upper=metadata[\"columns\"][col][\"upper\"],\n",
    "                        nullable=nullable\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        for col in col_categories[SSynthColumnType.ORDINAL]:\n",
    "            constraints[col] = ChainTransformer(\n",
    "                [LabelTransformer(nullable=nullable), OneHotEncoder()]\n",
    "            )\n",
    "    else:\n",
    "        for col in col_categories[SSynthColumnType.CATEGORICAL]:\n",
    "            constraints[col] = LabelTransformer(nullable=nullable)\n",
    "        for col in col_categories[SSynthColumnType.CONTINUOUS]:\n",
    "            constraints[col] = BinTransformer(nullable=nullable)\n",
    "        for col in col_categories[SSynthColumnType.DATETIME]:\n",
    "            constraints[col] = ChainTransformer(\n",
    "                [\n",
    "                    DateTimeTransformer(),\n",
    "                    BinTransformer(bins=20, nullable=nullable),\n",
    "                ]\n",
    "            )\n",
    "        for col in col_categories[SSynthColumnType.ORDINAL]:\n",
    "            constraints[col] = LabelTransformer(nullable=nullable)\n",
    "    print(constraints)\n",
    "    return TableTransformer.create(\n",
    "        data=private_data,\n",
    "        style=style,\n",
    "        nullable=nullable,\n",
    "        constraints=constraints,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5683cdfe-8206-494f-b367-d4dc91ef9a36",
   "metadata": {},
   "source": [
    "## Synthesize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d810f888-648a-4ad7-8a0a-2dceb5cf8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_json_pums = {\n",
    "    \"dataset_name\": \"PENGUIN\",\n",
    "    \"synth_name\": \"dpctgan\",\n",
    "    \"epsilon\": 0.1,\n",
    "    \"delta\": 0.00001,\n",
    "    \"synth_params\": {},\n",
    "    \"select_cols\": [],\n",
    "    \"mul_matrix\": [],\n",
    "    \"nullable\": True,\n",
    "    \"condition\": None,\n",
    "    \"nb_samples\": None,\n",
    "    \"table_transformer_style\": \"gan\",\n",
    "}\n",
    "query_json_pums = SmartnoiseSynthModel.model_validate(query_json_pums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c20bc-6dfa-41fd-aa41-de9beb6bd4ee",
   "metadata": {},
   "source": [
    "### PUMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2506595c-5991-432a-8c62-4fc25392343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pums_private_data = pd.read_csv(\"https://raw.githubusercontent.com/opendp/smartnoise-sdk/main/datasets/PUMS.csv\")\n",
    "print(pums_private_data.head())\n",
    "pums_metadata = {\n",
    "    \"columns\": {\n",
    "        \"age\": {'type': 'int', 'lower': 18, 'upper': 70},\n",
    "        \"sex\": {'type': 'boolean'},\n",
    "        \"educ\": {'type': 'int', 'cardinality': 14},\n",
    "        \"race\": {'type': 'int', 'cardinality': 6},\n",
    "        \"income\": {'type': 'float', 'lower': 0.0, 'upper': 500_000},\n",
    "        \"married\": {'type': 'boolean'},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a7528-aa24-44dd-9d53-877378936e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pums_private_data = _preprocess_data(pums_private_data, query_json_pums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee728264",
   "metadata": {},
   "outputs": [],
   "source": [
    "pums_transformer = _prepare_data_transformer(pums_metadata, pums_private_data, query_json_pums)\n",
    "pums_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866716d0-d77c-428c-9de2-93f9f200908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pums_encoded = pums_transformer.fit_transform(pums_private_data, epsilon=0.0)\n",
    "pums_transformer.odometer.spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee5ca4f-a82a-4641-8aa3-b595737ae4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Synthesizer.create(\n",
    "    synth=query_json_pums.synth_name,\n",
    "    epsilon=query_json_pums.epsilon,\n",
    "    verbose=True,\n",
    "    **query_json_pums.synth_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    data=pums_private_data,\n",
    "    transformer=pums_transformer, #pums_transformer,\n",
    "    preprocessor_eps=0.0, #0.0,  # will error if not 0.\n",
    "    #nullable=query_json_pums.nullable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc0d04-2f94-4aa0-ba9e-29a297f0b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c0c406-15db-480f-a122-e9c9e0350677",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model.sample(5)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5928db-cae0-4690-8f17-4cdb4ca50859",
   "metadata": {},
   "source": [
    "### Penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5af1f-e906-4366-b6bb-576615c00d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_private_data = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv\", index_col=None)\n",
    "print(penguin_private_data.head())\n",
    "penguin_metadata = {\n",
    " 'max_ids': 1,\n",
    " 'row_privacy': True,\n",
    " 'censor_dims': False,\n",
    " 'columns': {\n",
    "   'species': {'type': 'string', 'cardinality': 3,'categories': ['Adelie', 'Chinstrap', 'Gentoo']},\n",
    "   'island': {'type': 'string', 'cardinality': 3, 'categories': ['Torgersen', 'Biscoe', 'Dream']},\n",
    "   'bill_length_mm': {'type': 'float', 'lower': 30.0, 'upper': 65.0},\n",
    "   'bill_depth_mm': {'type': 'float', 'lower': 13.0, 'upper': 23.0},\n",
    "   'flipper_length_mm': {'type': 'float', 'lower': 150.0, 'upper': 250.0},\n",
    "   'body_mass_g': {'type': 'float', 'lower': 2000.0, 'upper': 7000.0},\n",
    "   'sex': {'type': 'string', 'cardinality': 2,'categories': ['MALE', 'FEMALE']}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19990d4-8529-451a-bcca-9c3ebc2b1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_json_penguin = {\n",
    "    \"dataset_name\": \"PENGUIN\",\n",
    "    \"synth_name\": \"dpctgan\",\n",
    "    \"epsilon\": 0.1,\n",
    "    \"delta\": 0.00001,\n",
    "    \"select_cols\": [\"bill_length_mm\"],\n",
    "    \"synth_params\": {\n",
    "        \"embedding_dim\": 128, \n",
    "        \"generator_dim\": (256, 256), \n",
    "        \"discriminator_dim\": (256, 256),\n",
    "        \"batch_size\": 50\n",
    "    },\n",
    "    \"mul_matrix\": [],\n",
    "    \"nullable\": True,\n",
    "    \"table_transformer_style\": \"gan\",\n",
    "}\n",
    "query_json_penguin = SmartnoiseSynthModel.model_validate(query_json_penguin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5a612-43a5-4d2a-b819-f32c9159693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Synthesizer.create(\n",
    "    synth=query_json_penguin.synth_name,\n",
    "    epsilon=query_json_penguin.epsilon,\n",
    "    verbose=True,\n",
    "    **query_json_penguin.synth_params,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30006e6b-e617-4cfb-a340-550e218d0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_private_data = _preprocess_data(penguin_private_data, query_json_penguin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c786d59-5b72-45da-b347-62b2be7c3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_transformer = _prepare_data_transformer(penguin_metadata, penguin_private_data, query_json_penguin)\n",
    "penguin_transformer.transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e0981-3dea-4452-90be-33f8a5bea732",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_encoded = penguin_transformer.fit_transform(penguin_private_data, epsilon=0.0)\n",
    "penguin_transformer.odometer.spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c665d49-58ac-4033-9f6c-b7532b074452",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Synthesizer.create(\n",
    "    synth=query_json_penguin.synth_name,\n",
    "    epsilon=query_json_penguin.epsilon,\n",
    "    **query_json_penguin.synth_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f6b0b4-cb4b-45c2-b6ea-8a4a5e5e779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    data=penguin_private_data,\n",
    "    transformer=penguin_transformer,\n",
    "    preprocessor_eps=0.0, #0.0,  # will error if not 0.\n",
    "    nullable=query_json_penguin.nullable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5888ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model.sample(5)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0180fe4-92be-4103-b162-aeed19605c6a",
   "metadata": {},
   "source": [
    "## Serialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26c63efb-9b18-451c-bf40-6eaa92a22f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snsynth.pytorch.nn.dpctgan.DPCTGAN at 0x7f9962742590>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from base64 import b64encode\n",
    "def serialise_model(model) -> str:\n",
    "    serialised = b64encode(pickle.dumps(model))\n",
    "    return serialised.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1352a33f-0279-4ff5-a8f5-db618d85090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model = serialise_model(model)\n",
    "str_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ffa4035-12d6-464b-bf5b-ad4f8c1174f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b64_model = base64.b64decode(str_model)\n",
    "b64_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388eae19-47cd-461a-a8c5-943f8cb92a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = pickle.loads(b64_model)\n",
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5cd4e285-8a2a-4609-a066-8881e85fa8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bill_length_mm\n",
      "0       46.956818\n",
      "1       45.232080\n",
      "2       55.124942\n",
      "3       50.191850\n",
      "4       57.324367\n"
     ]
    }
   ],
   "source": [
    "samples = new_model.sample(5)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a2711a0-087a-47a5-93d3-719d9618e0b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type DPCTGAN is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m j_obj \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/json/encoder.py:200\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    202\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/json/encoder.py:258\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    255\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type DPCTGAN is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "j_obj = json.dumps(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "548362da-b1f6-4550-9660-c8e61c49d840",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m pickled_model \u001b[38;5;241m=\u001b[39m b64encode(pickle\u001b[38;5;241m.\u001b[39mdumps(model))\n\u001b[1;32m      6\u001b[0m depickled_model \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64decode(pickled_model)\n\u001b[0;32m----> 7\u001b[0m json_model \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepickled_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/json/__init__.py:341\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "from base64 import b64encode\n",
    "pickled_model = b64encode(pickle.dumps(model))\n",
    "depickled_model = base64.b64decode(pickled_model)\n",
    "json_model = json.loads(depickled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e40bd0-3a88-4f08-9922-2c76b349d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = json_model.sample(100)\n",
    "print(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
