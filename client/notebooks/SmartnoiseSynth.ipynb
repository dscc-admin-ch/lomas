{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ffd914-9ebf-47ac-ba27-282390de1fc8",
   "metadata": {},
   "source": [
    "# Smartnoise Synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9e7614e-3c1c-4a12-b1e0-235e1e42ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lomas_client import Client\n",
    "from snsynth import Synthesizer # Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4407847c-dd68-4655-84a6-8013afd4ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_URL = \"http://lomas_server\"\n",
    "USER_NAME = \"Dr. Antartica\"\n",
    "DATASET_NAME = \"PENGUIN\"\n",
    "client = Client(url=APP_URL, user_name = USER_NAME, dataset_name = DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e45a43df-7f54-45d5-bdf9-2e9f3fad4b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_ids': 1,\n",
       " 'row_privacy': True,\n",
       " 'censor_dims': False,\n",
       " 'columns': {'species': {'type': 'string',\n",
       "   'cardinality': 3,\n",
       "   'categories': ['Adelie', 'Chinstrap', 'Gentoo']},\n",
       "  'island': {'type': 'string',\n",
       "   'cardinality': 3,\n",
       "   'categories': ['Torgersen', 'Biscoe', 'Dream']},\n",
       "  'bill_length_mm': {'type': 'float', 'lower': 30.0, 'upper': 65.0},\n",
       "  'bill_depth_mm': {'type': 'float', 'lower': 13.0, 'upper': 23.0},\n",
       "  'flipper_length_mm': {'type': 'float', 'lower': 150.0, 'upper': 250.0},\n",
       "  'body_mass_g': {'type': 'float', 'lower': 2000.0, 'upper': 7000.0},\n",
       "  'sex': {'type': 'string',\n",
       "   'cardinality': 2,\n",
       "   'categories': ['MALE', 'FEMALE']}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguin_metadata = client.get_dataset_metadata()\n",
    "penguin_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09010e63-2a10-4d97-a6bb-8aa9fa1d8709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mwem', 'dpctgan', 'patectgan', 'mst', 'pacsynth', 'dpgan', 'pategan', 'aim']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Synthesizer.list_synthesizers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ba6cf-4de0-4128-b082-649402d11db1",
   "metadata": {},
   "source": [
    "### DPCTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57dfb6ec-1371-41b6-8546-6540ee1e3ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epsilon_cost': 2.0, 'delta_cost': 0.0001}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = client.estimate_smartnoise_synth_cost(\n",
    "    synth_name=\"dpctgan\",\n",
    "    epsilon= 2.0,\n",
    "    delta = 0.0001,\n",
    "    select_cols = [\"bill_length_mm\"],\n",
    "    mul_matrix = [],\n",
    "    synth_params = {},\n",
    "    nullable = True,\n",
    "    table_transformer_style = \"gan\",\n",
    ")\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c18db6fa-7160-46f8-b299-68a54448afd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query_response': <snsynth.pytorch.nn.dpctgan.DPCTGAN at 0x7f2ee55f5790>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = client.smartnoise_synth_query(\n",
    "    synth_name=\"dpctgan\",\n",
    "    epsilon= 2.0,\n",
    "    delta = 0.0001,\n",
    "    select_cols = [\"bill_length_mm\"],\n",
    "    mul_matrix = [],\n",
    "    synth_params = {\n",
    "        \"embedding_dim\": 128, \n",
    "        \"generator_dim\": (256, 256), \n",
    "        \"discriminator_dim\": (256, 256),\n",
    "        \"batch_size\": 2\n",
    "    },\n",
    "    nullable = True,\n",
    "    table_transformer_style = \"gan\",\n",
    "    dummy = True\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49ce94e8-bfdb-4f3a-9fcc-2c7b2d3f6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = res[\"query_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cac5d5bc-abb6-4d40-a944-eeec22233297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.001299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.016453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.126438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.521182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.010460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bill_length_mm\n",
       "0       30.001299\n",
       "1       30.016453\n",
       "2       30.126438\n",
       "3       30.521182\n",
       "4       30.010460"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "451df18a-6621-4025-807c-af7d792de539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DPCTGAN'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cda6189a-487f-4b68-b76c-0964d8123ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/usr/local/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query_response': <snsynth.pytorch.nn.dpctgan.DPCTGAN at 0x7f2e11362fd0>}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = client.smartnoise_synth_query(\n",
    "    synth_name=\"dpctgan\",\n",
    "    epsilon= 2.0,\n",
    "    delta = 0.0001,\n",
    "    select_cols = [],\n",
    "    mul_matrix = [],\n",
    "    synth_params = {\n",
    "        \"embedding_dim\": 128, \n",
    "        \"generator_dim\": (256, 256), \n",
    "        \"discriminator_dim\": (256, 256),\n",
    "        \"batch_size\": 2\n",
    "    },\n",
    "    nullable = True,\n",
    "    table_transformer_style = \"gan\",\n",
    "    dummy = True\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f51ad07c-fae3-4d2b-a11c-250c3719a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_full = res[\"query_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0688163-bada-4e2f-b908-bf9339fe108d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_embedding_dim', '_generator_dim', '_discriminator_dim', '_generator_lr', '_generator_decay', '_discriminator_lr', '_discriminator_decay', '_batch_size', '_discriminator_steps', '_verbose', '_epochs', 'pac', 'sigma', 'disabled_dp', 'delta', 'max_per_sample_grad_norm', 'epsilon', 'epsilon_list', 'alpha_list', 'loss_d_list', 'loss_g_list', 'verbose', 'loss', '_device', '_transformer', '_data_sampler', '_generator'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(model_full).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66012424-92eb-42d6-9456-148de848b3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_embedding_dim': 128,\n",
       " '_generator_dim': [256, 256],\n",
       " '_discriminator_dim': [256, 256],\n",
       " '_generator_lr': 0.0002,\n",
       " '_generator_decay': 1e-06,\n",
       " '_discriminator_lr': 0.0002,\n",
       " '_discriminator_decay': 1e-06,\n",
       " '_batch_size': 2,\n",
       " '_discriminator_steps': 1,\n",
       " '_verbose': True,\n",
       " '_epochs': 300,\n",
       " 'pac': 1,\n",
       " 'sigma': 5,\n",
       " 'disabled_dp': False,\n",
       " 'delta': 0.0001,\n",
       " 'max_per_sample_grad_norm': 1.0,\n",
       " 'epsilon': 2.0,\n",
       " 'epsilon_list': [0.06572878196944024,\n",
       "  0.11987352690056335,\n",
       "  0.17187859626230675,\n",
       "  0.21446924519128757,\n",
       "  0.25100231533443196,\n",
       "  0.28359070972032546,\n",
       "  0.3133680752302131,\n",
       "  0.34098560828704494,\n",
       "  0.36688714227530783,\n",
       "  0.3914202376731256,\n",
       "  0.414705143957511,\n",
       "  0.43696518696468334,\n",
       "  0.4583646095635996,\n",
       "  0.47902082829201037,\n",
       "  0.49896752943154316,\n",
       "  0.5181722205213338,\n",
       "  0.5369391481901767,\n",
       "  0.5551931497428809,\n",
       "  0.5728767459042297,\n",
       "  0.5902865244242865,\n",
       "  0.6071306813066307,\n",
       "  0.6236976482533867,\n",
       "  0.6400007773945324,\n",
       "  0.6557263394732112,\n",
       "  0.67145190155189,\n",
       "  0.6867434254837599,\n",
       "  0.7016289846706376,\n",
       "  0.7165145438575152,\n",
       "  0.7312605173156399,\n",
       "  0.7453074708830356,\n",
       "  0.7593544244504311,\n",
       "  0.7734013780178268,\n",
       "  0.7873566194927203,\n",
       "  0.8005663600337993,\n",
       "  0.8137761005748784,\n",
       "  0.8269858411159575,\n",
       "  0.8401955816570367,\n",
       "  0.8532912982085326,\n",
       "  0.8656652136619357,\n",
       "  0.8780391291153389,\n",
       "  0.8904130445687419,\n",
       "  0.902786960022145,\n",
       "  0.915160875475548,\n",
       "  0.9275347909289513,\n",
       "  0.9391121804656686,\n",
       "  0.9506516541399539,\n",
       "  0.9621911278142392,\n",
       "  0.9737306014885243,\n",
       "  0.9852700751628094,\n",
       "  0.9968095488370949,\n",
       "  1.00834902251138,\n",
       "  1.0197668173627903,\n",
       "  1.0304732279607007,\n",
       "  1.0411796385586114,\n",
       "  1.051886049156522,\n",
       "  1.0625924597544327,\n",
       "  1.0732988703523432,\n",
       "  1.0840052809502536,\n",
       "  1.0947116915481643,\n",
       "  1.105418102146075,\n",
       "  1.1161245127439856,\n",
       "  1.1267497088595688,\n",
       "  1.1366244305021218,\n",
       "  1.1464991521446748,\n",
       "  1.1563738737872276,\n",
       "  1.1662485954297805,\n",
       "  1.1761233170723335,\n",
       "  1.1859980387148863,\n",
       "  1.1958727603574393,\n",
       "  1.2057474819999923,\n",
       "  1.215622203642545,\n",
       "  1.225496925285098,\n",
       "  1.235371646927651,\n",
       "  1.2452463685702038,\n",
       "  1.2551210902127568,\n",
       "  1.2649286182659543,\n",
       "  1.2738900637283486,\n",
       "  1.2828515091907433,\n",
       "  1.2918129546531376,\n",
       "  1.3007744001155324,\n",
       "  1.3097358455779267,\n",
       "  1.3186972910403214,\n",
       "  1.3276587365027162,\n",
       "  1.3366201819651105,\n",
       "  1.3455816274275052,\n",
       "  1.3545287689461694,\n",
       "  1.3634072712663041,\n",
       "  1.372261580387676,\n",
       "  1.3810571532067895,\n",
       "  1.3898237299647411,\n",
       "  1.398536386919549,\n",
       "  1.4072205490840315,\n",
       "  1.4158503038067347,\n",
       "  1.4244575987070487,\n",
       "  1.4330044648253377,\n",
       "  1.4415406819482313,\n",
       "  1.4500046730852865,\n",
       "  1.4584686642223417,\n",
       "  1.466856987283351,\n",
       "  1.4752381170578464,\n",
       "  1.4835677360365453,\n",
       "  1.4918660180626504,\n",
       "  1.500143533186523,\n",
       "  1.5083589810739055,\n",
       "  1.5165744289612877,\n",
       "  1.5247239215059571,\n",
       "  1.5328565488597818,\n",
       "  1.5409680738365266,\n",
       "  1.5490178942574637,\n",
       "  1.5570677146784013,\n",
       "  1.5650660374005465,\n",
       "  1.5730330644847705,\n",
       "  1.5810000915689946,\n",
       "  1.5888931556844572,\n",
       "  1.5967774030236497,\n",
       "  1.60465629761218,\n",
       "  1.6124577787935312,\n",
       "  1.6202592599748824,\n",
       "  1.6280499305230605,\n",
       "  1.6357686591292726,\n",
       "  1.643487387735485,\n",
       "  1.6511989865020278,\n",
       "  1.658834976111318,\n",
       "  1.6664709657206083,\n",
       "  1.6741069553298984,\n",
       "  1.6816663627364155,\n",
       "  1.6892196269225157,\n",
       "  1.6967728911086155,\n",
       "  1.7042729341358085,\n",
       "  1.7117434864679715,\n",
       "  1.7192140388001342,\n",
       "  1.726665318306382,\n",
       "  1.7340531723493802,\n",
       "  1.7414410263923783,\n",
       "  1.7488288804353767,\n",
       "  1.7561598585269635,\n",
       "  1.7634650278410933,\n",
       "  1.7707701971552232,\n",
       "  1.7780753006156722,\n",
       "  1.7852977987567549,\n",
       "  1.7925202968978375,\n",
       "  1.7997427950389202,\n",
       "  1.8069517149149157,\n",
       "  1.8140915554343013,\n",
       "  1.821231395953687,\n",
       "  1.8283712364730722,\n",
       "  1.8354970102973196,\n",
       "  1.8425542067418883,\n",
       "  1.849611403186457,\n",
       "  1.8566685996310257,\n",
       "  1.8637249716681408,\n",
       "  1.8706995375803062,\n",
       "  1.8776741034924718,\n",
       "  1.8846486694046374,\n",
       "  1.891623235316803,\n",
       "  1.8985420882446034,\n",
       "  1.905434037162313,\n",
       "  1.9123259860800224,\n",
       "  1.919217934997732,\n",
       "  1.9260972071614433,\n",
       "  1.9329065526181821,\n",
       "  1.939715898074921,\n",
       "  1.9465252435316602,\n",
       "  1.953334588988399,\n",
       "  1.9601078636104454,\n",
       "  1.9668346191352388,\n",
       "  1.9735613746600322,\n",
       "  1.9802881301848256,\n",
       "  1.9870148857096195,\n",
       "  1.9936992904369917,\n",
       "  2.0003434695544065],\n",
       " 'alpha_list': [63.0,\n",
       "  63.0,\n",
       "  55.0,\n",
       "  46.0,\n",
       "  41.0,\n",
       "  37.0,\n",
       "  34.0,\n",
       "  32.0,\n",
       "  30.0,\n",
       "  29.0,\n",
       "  27.0,\n",
       "  26.0,\n",
       "  25.0,\n",
       "  24.0,\n",
       "  24.0,\n",
       "  23.0,\n",
       "  22.0,\n",
       "  22.0,\n",
       "  21.0,\n",
       "  21.0,\n",
       "  20.0,\n",
       "  20.0,\n",
       "  19.0,\n",
       "  19.0,\n",
       "  19.0,\n",
       "  18.0,\n",
       "  18.0,\n",
       "  18.0,\n",
       "  17.0,\n",
       "  17.0,\n",
       "  17.0,\n",
       "  17.0,\n",
       "  16.0,\n",
       "  16.0,\n",
       "  16.0,\n",
       "  16.0,\n",
       "  16.0,\n",
       "  15.0,\n",
       "  15.0,\n",
       "  15.0,\n",
       "  15.0,\n",
       "  15.0,\n",
       "  15.0,\n",
       "  15.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  12.0,\n",
       "  10.9,\n",
       "  10.9,\n",
       "  10.9,\n",
       "  10.9,\n",
       "  10.9,\n",
       "  10.9,\n",
       "  10.9,\n",
       "  10.9,\n",
       "  10.9,\n",
       "  10.9,\n",
       "  10.8,\n",
       "  10.8,\n",
       "  10.7,\n",
       "  10.7,\n",
       "  10.6,\n",
       "  10.6,\n",
       "  10.5,\n",
       "  10.5,\n",
       "  10.4,\n",
       "  10.4,\n",
       "  10.3,\n",
       "  10.3,\n",
       "  10.3,\n",
       "  10.2,\n",
       "  10.2,\n",
       "  10.1,\n",
       "  10.1,\n",
       "  10.0,\n",
       "  10.0,\n",
       "  10.0,\n",
       "  9.9,\n",
       "  9.9,\n",
       "  9.8,\n",
       "  9.8,\n",
       "  9.8,\n",
       "  9.7,\n",
       "  9.7,\n",
       "  9.7,\n",
       "  9.6,\n",
       "  9.6,\n",
       "  9.5,\n",
       "  9.5,\n",
       "  9.5,\n",
       "  9.4,\n",
       "  9.4,\n",
       "  9.4,\n",
       "  9.3,\n",
       "  9.3,\n",
       "  9.3,\n",
       "  9.3,\n",
       "  9.2,\n",
       "  9.2,\n",
       "  9.2,\n",
       "  9.1,\n",
       "  9.1,\n",
       "  9.1,\n",
       "  9.0,\n",
       "  9.0,\n",
       "  9.0,\n",
       "  9.0,\n",
       "  8.9,\n",
       "  8.9,\n",
       "  8.9,\n",
       "  8.8,\n",
       "  8.8,\n",
       "  8.8,\n",
       "  8.8,\n",
       "  8.7,\n",
       "  8.7,\n",
       "  8.7,\n",
       "  8.7,\n",
       "  8.6,\n",
       "  8.6,\n",
       "  8.6,\n",
       "  8.6,\n",
       "  8.5,\n",
       "  8.5,\n",
       "  8.5,\n",
       "  8.5,\n",
       "  8.5,\n",
       "  8.4,\n",
       "  8.4,\n",
       "  8.4,\n",
       "  8.4,\n",
       "  8.3,\n",
       "  8.3,\n",
       "  8.3,\n",
       "  8.3,\n",
       "  8.3,\n",
       "  8.2,\n",
       "  8.2,\n",
       "  8.2,\n",
       "  8.2,\n",
       "  8.2,\n",
       "  8.1,\n",
       "  8.1],\n",
       " 'loss_d_list': [tensor(1.4735, requires_grad=True),\n",
       "  tensor(1.5704, requires_grad=True),\n",
       "  tensor(1.4983, requires_grad=True),\n",
       "  tensor(1.4978, requires_grad=True),\n",
       "  tensor(1.3967, requires_grad=True),\n",
       "  tensor(1.4655, requires_grad=True),\n",
       "  tensor(1.4603, requires_grad=True),\n",
       "  tensor(1.4985, requires_grad=True),\n",
       "  tensor(1.5420, requires_grad=True),\n",
       "  tensor(1.5253, requires_grad=True),\n",
       "  tensor(1.5038, requires_grad=True),\n",
       "  tensor(1.5088, requires_grad=True),\n",
       "  tensor(1.5635, requires_grad=True),\n",
       "  tensor(1.4595, requires_grad=True),\n",
       "  tensor(1.5573, requires_grad=True),\n",
       "  tensor(1.4403, requires_grad=True),\n",
       "  tensor(1.4061, requires_grad=True),\n",
       "  tensor(1.3623, requires_grad=True),\n",
       "  tensor(1.5072, requires_grad=True),\n",
       "  tensor(1.5084, requires_grad=True),\n",
       "  tensor(1.3522, requires_grad=True),\n",
       "  tensor(1.5119, requires_grad=True),\n",
       "  tensor(1.5592, requires_grad=True),\n",
       "  tensor(1.4494, requires_grad=True),\n",
       "  tensor(1.5116, requires_grad=True),\n",
       "  tensor(1.5383, requires_grad=True),\n",
       "  tensor(1.4443, requires_grad=True),\n",
       "  tensor(1.4197, requires_grad=True),\n",
       "  tensor(1.4367, requires_grad=True),\n",
       "  tensor(1.4330, requires_grad=True),\n",
       "  tensor(1.5134, requires_grad=True),\n",
       "  tensor(1.4330, requires_grad=True),\n",
       "  tensor(1.4378, requires_grad=True),\n",
       "  tensor(1.4153, requires_grad=True),\n",
       "  tensor(1.4825, requires_grad=True),\n",
       "  tensor(1.5281, requires_grad=True),\n",
       "  tensor(1.4532, requires_grad=True),\n",
       "  tensor(1.5225, requires_grad=True),\n",
       "  tensor(1.4546, requires_grad=True),\n",
       "  tensor(1.4618, requires_grad=True),\n",
       "  tensor(1.4807, requires_grad=True),\n",
       "  tensor(1.4769, requires_grad=True),\n",
       "  tensor(1.4376, requires_grad=True),\n",
       "  tensor(1.4185, requires_grad=True),\n",
       "  tensor(1.5005, requires_grad=True),\n",
       "  tensor(1.4331, requires_grad=True),\n",
       "  tensor(1.4625, requires_grad=True),\n",
       "  tensor(1.4720, requires_grad=True),\n",
       "  tensor(1.3974, requires_grad=True),\n",
       "  tensor(1.4902, requires_grad=True),\n",
       "  tensor(1.4466, requires_grad=True),\n",
       "  tensor(1.4612, requires_grad=True),\n",
       "  tensor(1.5301, requires_grad=True),\n",
       "  tensor(1.4160, requires_grad=True),\n",
       "  tensor(1.4454, requires_grad=True),\n",
       "  tensor(1.5395, requires_grad=True),\n",
       "  tensor(1.3344, requires_grad=True),\n",
       "  tensor(1.4827, requires_grad=True),\n",
       "  tensor(1.5108, requires_grad=True),\n",
       "  tensor(1.5030, requires_grad=True),\n",
       "  tensor(1.4108, requires_grad=True),\n",
       "  tensor(1.5487, requires_grad=True),\n",
       "  tensor(1.4828, requires_grad=True),\n",
       "  tensor(1.3621, requires_grad=True),\n",
       "  tensor(1.4092, requires_grad=True),\n",
       "  tensor(1.3245, requires_grad=True),\n",
       "  tensor(1.3839, requires_grad=True),\n",
       "  tensor(1.4988, requires_grad=True),\n",
       "  tensor(1.4088, requires_grad=True),\n",
       "  tensor(1.3952, requires_grad=True),\n",
       "  tensor(1.3475, requires_grad=True),\n",
       "  tensor(1.5394, requires_grad=True),\n",
       "  tensor(1.4854, requires_grad=True),\n",
       "  tensor(1.3744, requires_grad=True),\n",
       "  tensor(1.4394, requires_grad=True),\n",
       "  tensor(1.4903, requires_grad=True),\n",
       "  tensor(1.4481, requires_grad=True),\n",
       "  tensor(1.4956, requires_grad=True),\n",
       "  tensor(1.4595, requires_grad=True),\n",
       "  tensor(1.4002, requires_grad=True),\n",
       "  tensor(1.3063, requires_grad=True),\n",
       "  tensor(1.4235, requires_grad=True),\n",
       "  tensor(1.4705, requires_grad=True),\n",
       "  tensor(1.4157, requires_grad=True),\n",
       "  tensor(1.4192, requires_grad=True),\n",
       "  tensor(1.4818, requires_grad=True),\n",
       "  tensor(1.4050, requires_grad=True),\n",
       "  tensor(1.3379, requires_grad=True),\n",
       "  tensor(1.4861, requires_grad=True),\n",
       "  tensor(1.3274, requires_grad=True),\n",
       "  tensor(1.2918, requires_grad=True),\n",
       "  tensor(1.5483, requires_grad=True),\n",
       "  tensor(1.4703, requires_grad=True),\n",
       "  tensor(1.4041, requires_grad=True),\n",
       "  tensor(1.5521, requires_grad=True),\n",
       "  tensor(1.4195, requires_grad=True),\n",
       "  tensor(1.3893, requires_grad=True),\n",
       "  tensor(1.4773, requires_grad=True),\n",
       "  tensor(1.5769, requires_grad=True),\n",
       "  tensor(1.5267, requires_grad=True),\n",
       "  tensor(1.4788, requires_grad=True),\n",
       "  tensor(1.4006, requires_grad=True),\n",
       "  tensor(1.5997, requires_grad=True),\n",
       "  tensor(1.4589, requires_grad=True),\n",
       "  tensor(1.3340, requires_grad=True),\n",
       "  tensor(1.4623, requires_grad=True),\n",
       "  tensor(1.4231, requires_grad=True),\n",
       "  tensor(1.4696, requires_grad=True),\n",
       "  tensor(1.5298, requires_grad=True),\n",
       "  tensor(1.4465, requires_grad=True),\n",
       "  tensor(1.4476, requires_grad=True),\n",
       "  tensor(1.3600, requires_grad=True),\n",
       "  tensor(1.3832, requires_grad=True),\n",
       "  tensor(1.6210, requires_grad=True),\n",
       "  tensor(1.2913, requires_grad=True),\n",
       "  tensor(1.3259, requires_grad=True),\n",
       "  tensor(1.5797, requires_grad=True),\n",
       "  tensor(1.4461, requires_grad=True),\n",
       "  tensor(1.4073, requires_grad=True),\n",
       "  tensor(1.5506, requires_grad=True),\n",
       "  tensor(1.4127, requires_grad=True),\n",
       "  tensor(1.3943, requires_grad=True),\n",
       "  tensor(1.4384, requires_grad=True),\n",
       "  tensor(1.2823, requires_grad=True),\n",
       "  tensor(1.4018, requires_grad=True),\n",
       "  tensor(1.4449, requires_grad=True),\n",
       "  tensor(1.3602, requires_grad=True),\n",
       "  tensor(1.3531, requires_grad=True),\n",
       "  tensor(1.5035, requires_grad=True),\n",
       "  tensor(1.4605, requires_grad=True),\n",
       "  tensor(1.2806, requires_grad=True),\n",
       "  tensor(1.4873, requires_grad=True),\n",
       "  tensor(1.3298, requires_grad=True),\n",
       "  tensor(1.4331, requires_grad=True),\n",
       "  tensor(1.3390, requires_grad=True),\n",
       "  tensor(1.5316, requires_grad=True),\n",
       "  tensor(1.3879, requires_grad=True),\n",
       "  tensor(1.3988, requires_grad=True),\n",
       "  tensor(1.4000, requires_grad=True),\n",
       "  tensor(1.2645, requires_grad=True),\n",
       "  tensor(1.3988, requires_grad=True),\n",
       "  tensor(1.4475, requires_grad=True),\n",
       "  tensor(1.4402, requires_grad=True),\n",
       "  tensor(1.1787, requires_grad=True),\n",
       "  tensor(1.4073, requires_grad=True),\n",
       "  tensor(1.3403, requires_grad=True),\n",
       "  tensor(1.3231, requires_grad=True),\n",
       "  tensor(1.3454, requires_grad=True),\n",
       "  tensor(1.3306, requires_grad=True),\n",
       "  tensor(1.4884, requires_grad=True),\n",
       "  tensor(1.3272, requires_grad=True),\n",
       "  tensor(1.4095, requires_grad=True),\n",
       "  tensor(1.3780, requires_grad=True),\n",
       "  tensor(1.3961, requires_grad=True),\n",
       "  tensor(1.4085, requires_grad=True),\n",
       "  tensor(1.4790, requires_grad=True),\n",
       "  tensor(1.4428, requires_grad=True),\n",
       "  tensor(1.5353, requires_grad=True),\n",
       "  tensor(1.4214, requires_grad=True),\n",
       "  tensor(1.3824, requires_grad=True),\n",
       "  tensor(1.4923, requires_grad=True),\n",
       "  tensor(1.4530, requires_grad=True),\n",
       "  tensor(1.4516, requires_grad=True),\n",
       "  tensor(1.3829, requires_grad=True),\n",
       "  tensor(1.4861, requires_grad=True),\n",
       "  tensor(1.4916, requires_grad=True),\n",
       "  tensor(1.5286, requires_grad=True),\n",
       "  tensor(1.4551, requires_grad=True),\n",
       "  tensor(1.4887, requires_grad=True),\n",
       "  tensor(1.3996, requires_grad=True)],\n",
       " 'loss_g_list': [tensor(0.6018, requires_grad=True),\n",
       "  tensor(0.6286, requires_grad=True),\n",
       "  tensor(0.5714, requires_grad=True),\n",
       "  tensor(0.5514, requires_grad=True),\n",
       "  tensor(0.5784, requires_grad=True),\n",
       "  tensor(0.5882, requires_grad=True),\n",
       "  tensor(0.5974, requires_grad=True),\n",
       "  tensor(0.6010, requires_grad=True),\n",
       "  tensor(0.6293, requires_grad=True),\n",
       "  tensor(0.6122, requires_grad=True),\n",
       "  tensor(0.6165, requires_grad=True),\n",
       "  tensor(0.5903, requires_grad=True),\n",
       "  tensor(0.6654, requires_grad=True),\n",
       "  tensor(0.6013, requires_grad=True),\n",
       "  tensor(0.6046, requires_grad=True),\n",
       "  tensor(0.6680, requires_grad=True),\n",
       "  tensor(0.4758, requires_grad=True),\n",
       "  tensor(0.6080, requires_grad=True),\n",
       "  tensor(0.6073, requires_grad=True),\n",
       "  tensor(0.6179, requires_grad=True),\n",
       "  tensor(0.5948, requires_grad=True),\n",
       "  tensor(0.5504, requires_grad=True),\n",
       "  tensor(0.6216, requires_grad=True),\n",
       "  tensor(0.5633, requires_grad=True),\n",
       "  tensor(0.6167, requires_grad=True),\n",
       "  tensor(0.5926, requires_grad=True),\n",
       "  tensor(0.5680, requires_grad=True),\n",
       "  tensor(0.6440, requires_grad=True),\n",
       "  tensor(0.5578, requires_grad=True),\n",
       "  tensor(0.6060, requires_grad=True),\n",
       "  tensor(0.6482, requires_grad=True),\n",
       "  tensor(0.5284, requires_grad=True),\n",
       "  tensor(0.5890, requires_grad=True),\n",
       "  tensor(0.5990, requires_grad=True),\n",
       "  tensor(0.5240, requires_grad=True),\n",
       "  tensor(0.5839, requires_grad=True),\n",
       "  tensor(0.5825, requires_grad=True),\n",
       "  tensor(0.5947, requires_grad=True),\n",
       "  tensor(0.5307, requires_grad=True),\n",
       "  tensor(0.6250, requires_grad=True),\n",
       "  tensor(0.6697, requires_grad=True),\n",
       "  tensor(0.6097, requires_grad=True),\n",
       "  tensor(0.6383, requires_grad=True),\n",
       "  tensor(0.6155, requires_grad=True),\n",
       "  tensor(0.5868, requires_grad=True),\n",
       "  tensor(0.6122, requires_grad=True),\n",
       "  tensor(0.5841, requires_grad=True),\n",
       "  tensor(0.6106, requires_grad=True),\n",
       "  tensor(0.5593, requires_grad=True),\n",
       "  tensor(0.6446, requires_grad=True),\n",
       "  tensor(0.7127, requires_grad=True),\n",
       "  tensor(0.6124, requires_grad=True),\n",
       "  tensor(0.6161, requires_grad=True),\n",
       "  tensor(0.6417, requires_grad=True),\n",
       "  tensor(0.5718, requires_grad=True),\n",
       "  tensor(0.5701, requires_grad=True),\n",
       "  tensor(0.6297, requires_grad=True),\n",
       "  tensor(0.6810, requires_grad=True),\n",
       "  tensor(0.6654, requires_grad=True),\n",
       "  tensor(0.6059, requires_grad=True),\n",
       "  tensor(0.6433, requires_grad=True),\n",
       "  tensor(0.6662, requires_grad=True),\n",
       "  tensor(0.6139, requires_grad=True),\n",
       "  tensor(0.6273, requires_grad=True),\n",
       "  tensor(0.6369, requires_grad=True),\n",
       "  tensor(0.5818, requires_grad=True),\n",
       "  tensor(0.6770, requires_grad=True),\n",
       "  tensor(0.5944, requires_grad=True),\n",
       "  tensor(0.6665, requires_grad=True),\n",
       "  tensor(0.5876, requires_grad=True),\n",
       "  tensor(0.5805, requires_grad=True),\n",
       "  tensor(0.6117, requires_grad=True),\n",
       "  tensor(0.6484, requires_grad=True),\n",
       "  tensor(0.5570, requires_grad=True),\n",
       "  tensor(0.6762, requires_grad=True),\n",
       "  tensor(0.6309, requires_grad=True),\n",
       "  tensor(0.6943, requires_grad=True),\n",
       "  tensor(0.6473, requires_grad=True),\n",
       "  tensor(0.5895, requires_grad=True),\n",
       "  tensor(0.6336, requires_grad=True),\n",
       "  tensor(0.6510, requires_grad=True),\n",
       "  tensor(0.5954, requires_grad=True),\n",
       "  tensor(0.6492, requires_grad=True),\n",
       "  tensor(0.7275, requires_grad=True),\n",
       "  tensor(0.6501, requires_grad=True),\n",
       "  tensor(0.5955, requires_grad=True),\n",
       "  tensor(0.6150, requires_grad=True),\n",
       "  tensor(0.5764, requires_grad=True),\n",
       "  tensor(0.5678, requires_grad=True),\n",
       "  tensor(0.6958, requires_grad=True),\n",
       "  tensor(0.6970, requires_grad=True),\n",
       "  tensor(0.5810, requires_grad=True),\n",
       "  tensor(0.6618, requires_grad=True),\n",
       "  tensor(0.6192, requires_grad=True),\n",
       "  tensor(0.5518, requires_grad=True),\n",
       "  tensor(0.6523, requires_grad=True),\n",
       "  tensor(0.5151, requires_grad=True),\n",
       "  tensor(0.6266, requires_grad=True),\n",
       "  tensor(0.6001, requires_grad=True),\n",
       "  tensor(0.5710, requires_grad=True),\n",
       "  tensor(0.5893, requires_grad=True),\n",
       "  tensor(0.6038, requires_grad=True),\n",
       "  tensor(0.5943, requires_grad=True),\n",
       "  tensor(0.6025, requires_grad=True),\n",
       "  tensor(0.5582, requires_grad=True),\n",
       "  tensor(0.6109, requires_grad=True),\n",
       "  tensor(0.5470, requires_grad=True),\n",
       "  tensor(0.5827, requires_grad=True),\n",
       "  tensor(0.5894, requires_grad=True),\n",
       "  tensor(0.6193, requires_grad=True),\n",
       "  tensor(0.6704, requires_grad=True),\n",
       "  tensor(0.5698, requires_grad=True),\n",
       "  tensor(0.7085, requires_grad=True),\n",
       "  tensor(0.6561, requires_grad=True),\n",
       "  tensor(0.7338, requires_grad=True),\n",
       "  tensor(0.6044, requires_grad=True),\n",
       "  tensor(0.6502, requires_grad=True),\n",
       "  tensor(0.5792, requires_grad=True),\n",
       "  tensor(0.5899, requires_grad=True),\n",
       "  tensor(0.7267, requires_grad=True),\n",
       "  tensor(0.5656, requires_grad=True),\n",
       "  tensor(0.5695, requires_grad=True),\n",
       "  tensor(0.7031, requires_grad=True),\n",
       "  tensor(0.7184, requires_grad=True),\n",
       "  tensor(0.6229, requires_grad=True),\n",
       "  tensor(0.6183, requires_grad=True),\n",
       "  tensor(0.5838, requires_grad=True),\n",
       "  tensor(0.6978, requires_grad=True),\n",
       "  tensor(0.6563, requires_grad=True),\n",
       "  tensor(0.6165, requires_grad=True),\n",
       "  tensor(0.7148, requires_grad=True),\n",
       "  tensor(0.5627, requires_grad=True),\n",
       "  tensor(0.6476, requires_grad=True),\n",
       "  tensor(0.5746, requires_grad=True),\n",
       "  tensor(0.6799, requires_grad=True),\n",
       "  tensor(0.7168, requires_grad=True),\n",
       "  tensor(0.5641, requires_grad=True),\n",
       "  tensor(0.6704, requires_grad=True),\n",
       "  tensor(0.6761, requires_grad=True),\n",
       "  tensor(0.6343, requires_grad=True),\n",
       "  tensor(0.7083, requires_grad=True),\n",
       "  tensor(0.6942, requires_grad=True),\n",
       "  tensor(0.5484, requires_grad=True),\n",
       "  tensor(0.5231, requires_grad=True),\n",
       "  tensor(0.6385, requires_grad=True),\n",
       "  tensor(0.6350, requires_grad=True),\n",
       "  tensor(0.6682, requires_grad=True),\n",
       "  tensor(0.6372, requires_grad=True),\n",
       "  tensor(0.6570, requires_grad=True),\n",
       "  tensor(0.6654, requires_grad=True),\n",
       "  tensor(0.5560, requires_grad=True),\n",
       "  tensor(0.5653, requires_grad=True),\n",
       "  tensor(0.7247, requires_grad=True),\n",
       "  tensor(0.6188, requires_grad=True),\n",
       "  tensor(0.6587, requires_grad=True),\n",
       "  tensor(0.6435, requires_grad=True),\n",
       "  tensor(0.4764, requires_grad=True),\n",
       "  tensor(0.6488, requires_grad=True),\n",
       "  tensor(0.6204, requires_grad=True),\n",
       "  tensor(0.7789, requires_grad=True),\n",
       "  tensor(0.7048, requires_grad=True),\n",
       "  tensor(0.5893, requires_grad=True),\n",
       "  tensor(0.6780, requires_grad=True),\n",
       "  tensor(0.5218, requires_grad=True),\n",
       "  tensor(0.6825, requires_grad=True),\n",
       "  tensor(0.6771, requires_grad=True),\n",
       "  tensor(0.6456, requires_grad=True),\n",
       "  tensor(0.5435, requires_grad=True),\n",
       "  tensor(0.6867, requires_grad=True),\n",
       "  tensor(0.6026, requires_grad=True)],\n",
       " 'verbose': True,\n",
       " 'loss': 'cross_entropy',\n",
       " '_device': device(type='cpu'),\n",
       " '_transformer': <snsynth.transform.table.TableTransformer at 0x7f2e0c321590>,\n",
       " '_data_sampler': <snsynth.pytorch.nn.ctgan.data_sampler.DataSampler at 0x7f2e0c305790>,\n",
       " '_generator': Generator(\n",
       "   (seq): Sequential(\n",
       "     (0): Residual(\n",
       "       (fc): Linear(in_features=136, out_features=256, bias=True)\n",
       "       (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU()\n",
       "     )\n",
       "     (1): Residual(\n",
       "       (fc): Linear(in_features=392, out_features=256, bias=True)\n",
       "       (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU()\n",
       "     )\n",
       "     (2): Linear(in_features=648, out_features=16, bias=True)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(model_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9424eeab-d140-474d-b0bb-a691a248200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_full.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adea62e2-2990-42e8-b10a-cbe9a4f886f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns) ==['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n",
    "       'flipper_length_mm', 'body_mass_g', 'sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98fd0aaa-56d4-42c8-a36e-395039be87be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snsynth.transform.type_map import TypeMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38122be-a94f-4a28-a944-bcf68af02187",
   "metadata": {},
   "outputs": [],
   "source": [
    "TypeMap.get_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0370113-c028-4d06-b3e8-cb68e16cc7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from snsynth import Synthesizer\n",
    "from snsynth.transform import (\n",
    "    AnonymizationTransformer,\n",
    "    BinTransformer,\n",
    "    ChainTransformer,\n",
    "    #DateTimeTransformer,\n",
    "    LabelTransformer,\n",
    "    MinMaxTransformer,\n",
    "    OneHotEncoder,\n",
    ")\n",
    "from snsynth.transform.table import TableTransformer\n",
    "\n",
    "from typing import Dict, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9073073-fe81-440d-b6f2-7d4300129cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snsynth.transform.datetime import DateTimeTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f931338-72ce-45f2-87c6-da95301dbc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Synthesizer.list_synthesizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c76df9-8046-4438-bd66-b18161dc7def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class SmartnoiseSynthModel(BaseModel):\n",
    "    \"\"\"Model input for a smarnoise-synth query\"\"\"\n",
    "\n",
    "    dataset_name: str\n",
    "    synth_name: str\n",
    "    epsilon: float = 0.0\n",
    "    delta: float = 0.0\n",
    "    select_cols: List = []\n",
    "    synth_params: dict = {}\n",
    "    mul_matrix: List = []\n",
    "    nullable: bool = True\n",
    "    condition: Optional[str] = None\n",
    "    nb_samples: Optional[int] = None\n",
    "    table_transformer_style: str = \"gan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627f54e-c652-4b0c-a940-ce980bb12223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import StrEnum\n",
    "class SSynthSynthesizer(StrEnum):\n",
    "    \"\"\"Synthesizer models for smartnoise synth\"\"\"\n",
    "\n",
    "    # Marginal Synthesizer\n",
    "    AIM = \"aim\"\n",
    "    MWEM = \"mwem\"\n",
    "    MST = \"mst\"\n",
    "    PAC_SYNTH = \"pacsynth\"\n",
    "\n",
    "    # Neural Network Synthesizer\n",
    "    DP_CTGAN = \"dpctgan\"\n",
    "    PATE_CTGAN = \"patectgan\"\n",
    "    PATE_GAN = \"pategan\"  # no documentation\n",
    "    DP_GAN = \"dpgan\"  # no documentation\n",
    "\n",
    "    # Hybrid Synthesizer\n",
    "    QUAIL = \"quail\"\n",
    "\n",
    "\n",
    "class SSynthTableTransStyle(StrEnum):\n",
    "    \"\"\"Transformer style for smartnoise synth\"\"\"\n",
    "\n",
    "    GAN = \"gan\"\n",
    "    CUBE = \"cube\"\n",
    "\n",
    "\n",
    "class SSynthColumnType(StrEnum):\n",
    "    \"\"\"Type of columns for SmartnoiseSynth transformer pre-processing\"\"\"\n",
    "\n",
    "    PRIVATE_ID = \"private_id\"\n",
    "    CATEGORICAL = \"categorical\"\n",
    "    CONTINUOUS = \"continuous\"\n",
    "    ORDINAL = \"ordinal\"\n",
    "    DATETIME = \"datetime\"\n",
    "\n",
    "\n",
    "SSYNTH_PRIVATE_COLUMN = \"uuid\"\n",
    "SSYNTH_DEFAULT_NB_SAMPLES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5171177-d04f-4464-897c-4bfefae959ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_data(\n",
    "        private_data: pd.DataFrame,\n",
    "        query_json: dict,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Preprocess the data based on the query parameters.\n",
    "\n",
    "        Args:\n",
    "            private_data (pd.DataFrame): Private data to be preprocessed\n",
    "            query_json (dict): (SmartnoiseSynthModelCost): JSON request object\n",
    "                select_cols (List[str]): List of columns to select\n",
    "                mul_matrix (List): Multiplication matrix for columns aggregations\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Preprocessed private data\n",
    "        \"\"\"\n",
    "        if query_json.select_cols:\n",
    "            try:\n",
    "                private_data = private_data[query_json.select_cols]\n",
    "            except KeyError as e:\n",
    "                raise ValueError(\n",
    "                    \"Error while selecting provided select_cols: \" + str(e)\n",
    "                ) from e\n",
    "\n",
    "        if query_json.mul_matrix:\n",
    "            try:\n",
    "                np_matrix = np.array(query_json.mul_matrix)\n",
    "                mul_private_data = private_data.to_numpy().dot(np_matrix.T)\n",
    "                private_data = pd.DataFrame(mul_private_data)\n",
    "            except ValueError as e:\n",
    "                raise ValueError(\n",
    "                    f\"Failed to multiply provided mul_matrix: {(str(e))}\"\n",
    "                ) from e\n",
    "        return private_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283a54c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _categorize_column(data: dict) -> str:\n",
    "    \"\"\"\n",
    "    Categorize the column based on its metadata.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Metadata of the column.\n",
    "\n",
    "    Returns:\n",
    "        str: Category of the column.\n",
    "    \"\"\"\n",
    "    match data[\"type\"]:\n",
    "        case \"string\" | \"boolean\":\n",
    "            return SSynthColumnType.CATEGORICAL\n",
    "        case \"int\" | \"float\":\n",
    "            if \"lower\" in data.keys():\n",
    "                return SSynthColumnType.CONTINUOUS\n",
    "            if \"cardinality\" in data.keys():\n",
    "                return SSynthColumnType.CATEGORICAL\n",
    "            return SSynthColumnType.ORDINAL\n",
    "        case \"datetime\":\n",
    "            return SSynthColumnType.DATETIME\n",
    "        case _:\n",
    "            raise ValueError(\n",
    "                f\"Unknown column type in metadata: {data['type']}\"\n",
    "            )\n",
    "\n",
    "def _get_column_by_types(\n",
    "    metadata,\n",
    "    select_cols: List[str],\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Sort the column in categories based on their types and metadata\n",
    "\n",
    "    Args:\n",
    "        metadata (Metadata): Metadata of the dataset\n",
    "        select_cols (List[str]): List of columns to select\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[str]]: Dictionnary of list of columns by categories\n",
    "    \"\"\"\n",
    "    col_categories: Dict[str, List[str]] = {\n",
    "        SSynthColumnType.CATEGORICAL: [],\n",
    "        SSynthColumnType.CONTINUOUS: [],\n",
    "        SSynthColumnType.DATETIME: [],\n",
    "        SSynthColumnType.ORDINAL: [],\n",
    "        SSynthColumnType.PRIVATE_ID: [],\n",
    "    }\n",
    "    for col_name, data in metadata[\"columns\"].items():\n",
    "        if select_cols and col_name not in select_cols:\n",
    "            continue\n",
    "        \n",
    "        if \"private_id\" in data.keys():\n",
    "            col_categories[SSynthColumnType.PRIVATE_ID].append(col_name)\n",
    "            continue\n",
    "\n",
    "        # Sort the column in categories based on their types and metadata\n",
    "        category = _categorize_column(data)\n",
    "        col_categories[category].append(col_name)\n",
    "\n",
    "    return col_categories\n",
    "\n",
    "def _prepare_data_transformer(\n",
    "    metadata,\n",
    "    private_data: pd.DataFrame,\n",
    "    query_json: dict,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates the transformer based on the metadata\n",
    "    The transformer is used to transform the data before synthesis and then\n",
    "    reverse the transformation after synthesis.\n",
    "    See https://docs.smartnoise.org/synth/transforms/index.html for documentation\n",
    "    See https://github.com/opendp/smartnoise-sdk/blob/main/synth/snsynth/\n",
    "        transform/type_map.py#L40 for get_transformer() method taken as basis.\n",
    "\n",
    "    Args:\n",
    "        metadata (Metadata): Metadata of the dataset\n",
    "        private_data\n",
    "        query_json (SmartnoiseSynthModelCost): JSON request object for the query\n",
    "            select_cols (List[str]): List of columns to select\n",
    "            nullable (bool): True is the data can have Null values, False otherwise\n",
    "            table_transformer_style: 'gan' or 'cube'\n",
    "\n",
    "    Returns:\n",
    "        table_tranformer (TableTransformer) to pre and post-process the data\n",
    "    \"\"\"\n",
    "    col_categories = _get_column_by_types(metadata, query_json.select_cols)\n",
    "    style = query_json.table_transformer_style\n",
    "    nullable = query_json.nullable\n",
    "\n",
    "    constraints = {}\n",
    "    for col in col_categories[SSynthColumnType.PRIVATE_ID]:\n",
    "        constraints[col] = AnonymizationTransformer(SSYNTH_PRIVATE_COLUMN)\n",
    "\n",
    "    if style == SSynthTableTransStyle.GAN:\n",
    "        for col in col_categories[SSynthColumnType.CATEGORICAL]:\n",
    "            constraints[col] = ChainTransformer(\n",
    "                [LabelTransformer(nullable=nullable), OneHotEncoder()]\n",
    "            )\n",
    "        for col in col_categories[SSynthColumnType.CONTINUOUS]:\n",
    "            constraints[col] = MinMaxTransformer(\n",
    "                lower=metadata[\"columns\"][col][\"lower\"],\n",
    "                upper=metadata[\"columns\"][col][\"upper\"],\n",
    "                nullable=nullable,\n",
    "            )\n",
    "        for col in col_categories[SSynthColumnType.DATETIME]:\n",
    "            constraints[col] = ChainTransformer(\n",
    "                [\n",
    "                    DateTimeTransformer(),\n",
    "                    MinMaxTransformer(\n",
    "                        lower=metadata[\"columns\"][col][\"lower\"],\n",
    "                        upper=metadata[\"columns\"][col][\"upper\"],\n",
    "                        nullable=nullable\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        for col in col_categories[SSynthColumnType.ORDINAL]:\n",
    "            constraints[col] = ChainTransformer(\n",
    "                [LabelTransformer(nullable=nullable), OneHotEncoder()]\n",
    "            )\n",
    "    else:\n",
    "        for col in col_categories[SSynthColumnType.CATEGORICAL]:\n",
    "            constraints[col] = LabelTransformer(nullable=nullable)\n",
    "        for col in col_categories[SSynthColumnType.CONTINUOUS]:\n",
    "            constraints[col] = BinTransformer(nullable=nullable)\n",
    "        for col in col_categories[SSynthColumnType.DATETIME]:\n",
    "            constraints[col] = ChainTransformer(\n",
    "                [\n",
    "                    DateTimeTransformer(),\n",
    "                    BinTransformer(bins=20, nullable=nullable),\n",
    "                ]\n",
    "            )\n",
    "        for col in col_categories[SSynthColumnType.ORDINAL]:\n",
    "            constraints[col] = LabelTransformer(nullable=nullable)\n",
    "    print(constraints)\n",
    "    return TableTransformer.create(\n",
    "        data=private_data,\n",
    "        style=style,\n",
    "        nullable=nullable,\n",
    "        constraints=constraints,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5683cdfe-8206-494f-b367-d4dc91ef9a36",
   "metadata": {},
   "source": [
    "## Synthesize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d810f888-648a-4ad7-8a0a-2dceb5cf8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_json_pums = {\n",
    "    \"dataset_name\": \"PENGUIN\",\n",
    "    \"synth_name\": \"dpctgan\",\n",
    "    \"epsilon\": 0.1,\n",
    "    \"delta\": 0.00001,\n",
    "    \"synth_params\": {},\n",
    "    \"select_cols\": [],\n",
    "    \"mul_matrix\": [],\n",
    "    \"nullable\": True,\n",
    "    \"condition\": None,\n",
    "    \"nb_samples\": None,\n",
    "    \"table_transformer_style\": \"gan\",\n",
    "}\n",
    "query_json_pums = SmartnoiseSynthModel.model_validate(query_json_pums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c20bc-6dfa-41fd-aa41-de9beb6bd4ee",
   "metadata": {},
   "source": [
    "### PUMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2506595c-5991-432a-8c62-4fc25392343c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pums_private_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/opendp/smartnoise-sdk/main/datasets/PUMS.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(pums_private_data\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      3\u001b[0m pums_metadata \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m18\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m70\u001b[39m},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     }\n\u001b[1;32m     12\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pums_private_data = pd.read_csv(\"https://raw.githubusercontent.com/opendp/smartnoise-sdk/main/datasets/PUMS.csv\")\n",
    "print(pums_private_data.head())\n",
    "pums_metadata = {\n",
    "    \"columns\": {\n",
    "        \"age\": {'type': 'int', 'lower': 18, 'upper': 70},\n",
    "        \"sex\": {'type': 'boolean'},\n",
    "        \"educ\": {'type': 'int', 'cardinality': 14},\n",
    "        \"race\": {'type': 'int', 'cardinality': 6},\n",
    "        \"income\": {'type': 'float', 'lower': 0.0, 'upper': 500_000},\n",
    "        \"married\": {'type': 'boolean'},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a7528-aa24-44dd-9d53-877378936e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pums_private_data = _preprocess_data(pums_private_data, query_json_pums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee728264",
   "metadata": {},
   "outputs": [],
   "source": [
    "pums_transformer = _prepare_data_transformer(pums_metadata, pums_private_data, query_json_pums)\n",
    "pums_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866716d0-d77c-428c-9de2-93f9f200908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pums_encoded = pums_transformer.fit_transform(pums_private_data, epsilon=0.0)\n",
    "pums_transformer.odometer.spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee5ca4f-a82a-4641-8aa3-b595737ae4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Synthesizer.create(\n",
    "    synth=query_json_pums.synth_name,\n",
    "    epsilon=query_json_pums.epsilon,\n",
    "    verbose=True,\n",
    "    **query_json_pums.synth_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    data=pums_private_data,\n",
    "    transformer=pums_transformer, #pums_transformer,\n",
    "    preprocessor_eps=0.0, #0.0,  # will error if not 0.\n",
    "    #nullable=query_json_pums.nullable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc0d04-2f94-4aa0-ba9e-29a297f0b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c0c406-15db-480f-a122-e9c9e0350677",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model.sample(5)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5928db-cae0-4690-8f17-4cdb4ca50859",
   "metadata": {},
   "source": [
    "### Penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5af1f-e906-4366-b6bb-576615c00d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_private_data = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv\", index_col=None)\n",
    "print(penguin_private_data.head())\n",
    "penguin_metadata = {\n",
    " 'max_ids': 1,\n",
    " 'row_privacy': True,\n",
    " 'censor_dims': False,\n",
    " 'columns': {\n",
    "   'species': {'type': 'string', 'cardinality': 3,'categories': ['Adelie', 'Chinstrap', 'Gentoo']},\n",
    "   'island': {'type': 'string', 'cardinality': 3, 'categories': ['Torgersen', 'Biscoe', 'Dream']},\n",
    "   'bill_length_mm': {'type': 'float', 'lower': 30.0, 'upper': 65.0},\n",
    "   'bill_depth_mm': {'type': 'float', 'lower': 13.0, 'upper': 23.0},\n",
    "   'flipper_length_mm': {'type': 'float', 'lower': 150.0, 'upper': 250.0},\n",
    "   'body_mass_g': {'type': 'float', 'lower': 2000.0, 'upper': 7000.0},\n",
    "   'sex': {'type': 'string', 'cardinality': 2,'categories': ['MALE', 'FEMALE']}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19990d4-8529-451a-bcca-9c3ebc2b1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_json_penguin = {\n",
    "    \"dataset_name\": \"PENGUIN\",\n",
    "    \"synth_name\": \"dpctgan\",\n",
    "    \"epsilon\": 0.1,\n",
    "    \"delta\": 0.00001,\n",
    "    \"select_cols\": [\"bill_length_mm\"],\n",
    "    \"synth_params\": {\n",
    "        \"embedding_dim\": 128, \n",
    "        \"generator_dim\": (256, 256), \n",
    "        \"discriminator_dim\": (256, 256),\n",
    "        \"batch_size\": 50\n",
    "    },\n",
    "    \"mul_matrix\": [],\n",
    "    \"nullable\": True,\n",
    "    \"table_transformer_style\": \"gan\",\n",
    "}\n",
    "query_json_penguin = SmartnoiseSynthModel.model_validate(query_json_penguin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5a612-43a5-4d2a-b819-f32c9159693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Synthesizer.create(\n",
    "    synth=query_json_penguin.synth_name,\n",
    "    epsilon=query_json_penguin.epsilon,\n",
    "    verbose=True,\n",
    "    **query_json_penguin.synth_params,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30006e6b-e617-4cfb-a340-550e218d0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_private_data = _preprocess_data(penguin_private_data, query_json_penguin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c786d59-5b72-45da-b347-62b2be7c3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_transformer = _prepare_data_transformer(penguin_metadata, penguin_private_data, query_json_penguin)\n",
    "penguin_transformer.transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e0981-3dea-4452-90be-33f8a5bea732",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_encoded = penguin_transformer.fit_transform(penguin_private_data, epsilon=0.0)\n",
    "penguin_transformer.odometer.spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c665d49-58ac-4033-9f6c-b7532b074452",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Synthesizer.create(\n",
    "    synth=query_json_penguin.synth_name,\n",
    "    epsilon=query_json_penguin.epsilon,\n",
    "    **query_json_penguin.synth_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f6b0b4-cb4b-45c2-b6ea-8a4a5e5e779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    data=penguin_private_data,\n",
    "    transformer=penguin_transformer,\n",
    "    preprocessor_eps=0.0, #0.0,  # will error if not 0.\n",
    "    nullable=query_json_penguin.nullable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5888ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model.sample(5)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0180fe4-92be-4103-b162-aeed19605c6a",
   "metadata": {},
   "source": [
    "## Serialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26c63efb-9b18-451c-bf40-6eaa92a22f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snsynth.pytorch.nn.dpctgan.DPCTGAN at 0x7f9962742590>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from base64 import b64encode\n",
    "def serialise_model(model) -> str:\n",
    "    serialised = b64encode(pickle.dumps(model))\n",
    "    return serialised.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1352a33f-0279-4ff5-a8f5-db618d85090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model = serialise_model(model)\n",
    "str_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ffa4035-12d6-464b-bf5b-ad4f8c1174f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b64_model = base64.b64decode(str_model)\n",
    "b64_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388eae19-47cd-461a-a8c5-943f8cb92a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = pickle.loads(b64_model)\n",
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5cd4e285-8a2a-4609-a066-8881e85fa8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bill_length_mm\n",
      "0       46.956818\n",
      "1       45.232080\n",
      "2       55.124942\n",
      "3       50.191850\n",
      "4       57.324367\n"
     ]
    }
   ],
   "source": [
    "samples = new_model.sample(5)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a2711a0-087a-47a5-93d3-719d9618e0b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type DPCTGAN is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m j_obj \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/json/encoder.py:200\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    202\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/json/encoder.py:258\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    255\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type DPCTGAN is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "j_obj = json.dumps(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "548362da-b1f6-4550-9660-c8e61c49d840",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m pickled_model \u001b[38;5;241m=\u001b[39m b64encode(pickle\u001b[38;5;241m.\u001b[39mdumps(model))\n\u001b[1;32m      6\u001b[0m depickled_model \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64decode(pickled_model)\n\u001b[0;32m----> 7\u001b[0m json_model \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepickled_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/json/__init__.py:341\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "from base64 import b64encode\n",
    "pickled_model = b64encode(pickle.dumps(model))\n",
    "depickled_model = base64.b64decode(pickled_model)\n",
    "json_model = json.loads(depickled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e40bd0-3a88-4f08-9922-2c76b349d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = json_model.sample(100)\n",
    "print(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
