# Default values for lomas_server.

# General stuff
nameOverride: ""
fullnameOverride: "lomas"

# MongoDB 
##########################################################################
mongodb:
  resources: {}
  fullnameOverride: "lomas-mongodb"
  max_pool_size: 100
  min_pool_size: 2
  max_connecting: 2
  architecture: standalone
  image:
    tag: "6.0.9-debian-11-r5"
  auth:
    enabled: true
    rootUser: root
    rootPassword: root_pwd # changeme
    usernames: [user] 
    passwords: [user_pwd] # changeme
    databases: [defaultdb]
  replicaCount: 1
  discoverable:
    allow: true
  security:
    networkPolicy: 
      enabled: true
  persistence:
    # Set this to "keep" to disable data pvc deletion when uninstalling the chart.
    # Subsequent installs will use the same pvc, restoring the state of the server.
    # Note: if the runtime_args.settings.develop_mode is set to True, the server
    # state will be reset (default datasets and budgets).
    resourcePolicy: ""


# Fast-API server
##########################################################################
server:  
  image:
    repository: dsccadminch/lomas_server
    imagePullPolicy: Always
    tag: sha-9ff59ad
  imagePullSecrets: []

  # Runtime args for server
  runtime_args:
    settings:
      develop_mode: True # !! Set this to false in production mode !!
      submit_limit: 300
      server:
        host_ip: "0.0.0.0"
        host_port: "8080"     
        log_level: "info"
        reload: True
        workers: 1 # Will be overwritten to one anyway for now.
        time_attack:
          method: "jitter" # or "stall"
          magnitude: 1
      dp_libraries:
        opendp:
          contrib: True
          floating_point: True
          honest_but_curious: True
      private_db_credentials: [] # list of credentials, eg. {credentials_name: "abc", db_type: "S3_DB", ...}


  service:
    type: ClusterIP
    port: 80

  ingress:
    enabled: true
    className: "nginx"
    annotations: 
      nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    hostname: "lomas-server.example.com"
  # Lomas server not meant to be replicated for now
  replicaCount: 1
  # Lomas server not intended to be autoscaled for now
  # autoscaling:
  #  enabled: false
  #  minReplicas: 1
  #  maxReplicas: 100
  #  targetCPUUtilizationPercentage: 80
  #  # targetMemoryUtilizationPercentage: 80

  # We leave unset stuff here
  serviceAccount:
    create: false
    annotations: {}
    name: ""
  resources: {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  podAnnotations: {}
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000
  nodeSelector: {}
  tolerations: []
  affinity: {}

# Lomas Administration Dashboard
##########################################################################
dashboard:
  create: true

  image:
    repository: dsccadminch/lomas_admin_dashboard
    pullPolicy: Always
    tag: latest
  imagePullSecrets: []

  # Runtime args for server
  serverConfig:
    address: "0.0.0.0"
    port: "8501"

  service:
    type: ClusterIP
    port: 80
 
  ingress:
    enabled: true
    className: "nginx"
    annotations: 
      nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    hostname: "lomas-admin-dashboard.lab.sspcloud.fr"
  # Lomas dashboard not meant to be replicated for now
  replicaCount: 1
  # Lomas dashboard not intended to be autoscaled for now
  # autoscaling:
  #  enabled: false
  #  minReplicas: 1
  #  maxReplicas: 100
  #  targetCPUUtilizationPercentage: 80
  #  # targetMemoryUtilizationPercentage: 80
  
  # We leave unset stuff here
  serviceAccount:
    create: false
    annotations: {}
    name: ""
  resources: {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  podAnnotations: {}
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000
  nodeSelector: {}
  tolerations: []
  affinity: {}

# Loki
##########################################################################
loki:
  service:
    port: 3100
    target_port: 3100
  config:
    auth_enabled: false
    limits_config:
      allow_structured_metadata: true
      volume_enabled: true
    server:
      http_listen_port: 3100
    common:
      ring:
        instance_addr: 0.0.0.0
        kvstore:
          store: inmemory
      replication_factor: 1
      path_prefix: /tmp/loki
    schema_config:
      configs:
        - from: "2025-01-10"
          store: tsdb
          object_store: filesystem
          schema: v13
          index:
            prefix: loki_index_
            period: 24h
    storage_config:
      tsdb_shipper:
        active_index_directory: /tmp/loki/index
        cache_location: /tmp/loki/index_cache
      filesystem:
        directory: /tmp/loki/chunks
    pattern_ingester:
      enabled: true

# Opentelemtry-Collector
##########################################################################
otel:
  service:
    port: 9090
  config:
    receiver:
      grpc_port: 4317
      http_port: 4318
    processors:
      batch:
        timeout: 5s
    exporter:
      prometheus_endpoint: 9090
    extension:
      health_check_port: 13133
      pprof_port: 1777
      zpages_port: 55679
    log_level: debug

# Prometheus
##########################################################################
prometheus:
  service:
    port: 9091
    target_port: 9091
  config:
    scrape_interval: 10s
    evaluation_interval: 10s

# Tempo
##########################################################################
tempo:
  service:
    type: ClusterIP
  fullnameOverride: "lomas-tempo"
  server:
    http_listen_port: 3100
  ingester:
    max_block_duration: 5m
  storage:
    trace:
      backend: local
      local:
        path: /var/tempo/traces
      wal:
        path: /var/tempo/wal
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: "0.0.0.0:4317"
        http:
          endpoint: "0.0.0.0:4318"
  persistence:
    enabled: false

# Grafana
##########################################################################
grafana:
  service:
    type: ClusterIP
    port: 3000

  fullnameOverride: "lomas-grafana-dashboard"

  rbac:
    create: false
    namespaced: true

  datasources: 
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          uid: prometheus
          access: proxy
          orgId: 1
          url: http://lomas-prometheus:9091
          basicAuth: false
          isDefault: false
          version: 1
          editable: true
          jsonData:
            httpMethod: GET
        - name: Tempo
          type: tempo
          uid: tempo
          access: proxy
          orgId: 1
          url: http://lomas-tempo:3100
          basicAuth: false
          isDefault: true
          version: 1
          editable: true
          apiVersion: 1
          stream_over_http_enabled: false
        - name: Loki
          type: loki
          uid: loki
          access: proxy
          orgId: 1
          url: http://lomas-loki:3100
          basicAuth: false
          isDefault: false
          version: 1
          editable: true
          jsonData:
            httpHeaderName1: "X-Scope-OrgID"
          secureJsonData:
            httpHeaderValue1: "tenant1"

  env:
    GF_SECURITY_ADMIN_USER: admin
    GF_SECURITY_ADMIN_PASSWORD: admin
  
  ingress:
    enabled: true
    hosts: 
      - "lomas-monitoring-dashboard.lab.sspcloud.fr"
  
  persistence:
    enabled: false
