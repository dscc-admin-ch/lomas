{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "363c238d-5925-4b4b-8f68-8ad84ea4705b",
   "metadata": {},
   "source": [
    "# Secure Data Disclosure on Kubernetes: Deployment and Server Administration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1363b-e87e-4d0e-bb3f-9af1a1b72b8d",
   "metadata": {},
   "source": [
    "This notebook showcases how a data owner could set up the service on a kubernetes cluster, add and make their data available to certain user. We will do this in a step by step fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de384c88-559e-4384-a49b-1664ffdd6692",
   "metadata": {},
   "source": [
    "## Deploying the service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba5946",
   "metadata": {},
   "source": [
    "### Building the server image\n",
    "The SDD service is comprised of a fastapi server and a MongoDB database for keeping state and administration. While the database image is public, the server image must first be built and pushed to a registry.\n",
    "\n",
    "NOTE: For now, the server configuration file is copied and put into the server container. This is of course not practical (and not safe, since the configuration file contains passwords and secrets) and will be updated in future versions. The `config/example_config.yaml` is the one that is copied into the container. One has to change it and rebuild+push the server container in order to change the server configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f688134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker login (=> use personal token from dockerhub, has to be done only once)\n",
    "\n",
    "!cd .. && docker build --target sdd_server_prod -t <your_registry>/sdd_server_prod:latest .\n",
    "!cd .. && docker push <your_registry>/sdd-poc-server:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3237b-6f13-4c52-a9f2-82d94f0b7e66",
   "metadata": {},
   "source": [
    "### Deploying the service Helm chart\n",
    "We use a Helm chart to deploy the service on a Kubernetes cluster. The sdd-server chart is located at `deploy/helm/charts/sdd_server`, let us change our working directory to this location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e249d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../deploy/helm/charts/sdd_server')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11075ea0",
   "metadata": {},
   "source": [
    "The `values.yaml` file contains all the configuration values for the service. We must now update the `image.repository` field to the one we pushed the server container image to. One can also change the url to which the service will be published with `ingress.hosts[0].host` (or disable this feature by setting `ingress.enabled` to `False`).\n",
    "\n",
    "    => Update `values.yaml` file\n",
    "\n",
    "As previously stated, the service is made up of a server and a MongoDB database. Before installing the chart, we must thus first download that dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe550e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 1 charts\n",
      "Downloading mongodb from repo oci://registry-1.docker.io/bitnamicharts\n",
      "Pulled: registry-1.docker.io/bitnamicharts/mongodb:13.18.1\n",
      "Digest: sha256:f3b2a691537260044746bc4a8898e9ae68e8c29864639737b6da920f99aebe97\n",
      "Deleting outdated charts\n"
     ]
    }
   ],
   "source": [
    "!helm dependency update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2913bce4",
   "metadata": {},
   "source": [
    "Now the chart is ready to be installed, so let the magic happen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm install -f values.yaml sdd-service ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d4837",
   "metadata": {},
   "source": [
    "The installation notes show the url at which the server is exposed. One can have a look at the api docummentation by visiting `<server_url>/docs`\n",
    "\n",
    "One can also check the whether the service started error free by using the `kubectl get all` command as well as inspecting the server logs with `kubectl logs <server-pod-name>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbebd54-8deb-46e6-b811-73ac74028569",
   "metadata": {},
   "source": [
    "## Administering the service by accessing the mongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2ec36f",
   "metadata": {},
   "source": [
    "Let's switch directory again and move to the administration script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ede728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../../../src/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8c8115",
   "metadata": {},
   "source": [
    "To interact with the mongoDB, we will need to install a few libraries. Let's do so by creating a python virtual environment and installing the dependencies listed in `admin_requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6863a6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting annotated-types==0.5.0 (from -r ../admin_requirements.txt (line 1))\n",
      "  Downloading annotated_types-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting anyio==3.7.1 (from -r ../admin_requirements.txt (line 2))\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting asttokens==2.4.0 (from -r ../admin_requirements.txt (line 3))\n",
      "  Downloading asttokens-2.4.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting backcall==0.2.0 (from -r ../admin_requirements.txt (line 4))\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: comm==0.1.4 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 5)) (0.1.4)\n",
      "Collecting debugpy==1.7.0 (from -r ../admin_requirements.txt (line 6))\n",
      "  Downloading debugpy-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: decorator==5.1.1 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 7)) (5.1.1)\n",
      "Collecting dnspython==2.4.2 (from -r ../admin_requirements.txt (line 8))\n",
      "  Downloading dnspython-2.4.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting executing==1.2.0 (from -r ../admin_requirements.txt (line 9))\n",
      "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting fastapi==0.103.1 (from -r ../admin_requirements.txt (line 10))\n",
      "  Downloading fastapi-0.103.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: idna==3.4 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 11)) (3.4)\n",
      "Collecting ipykernel==6.25.2 (from -r ../admin_requirements.txt (line 12))\n",
      "  Downloading ipykernel-6.25.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting ipython==8.15.0 (from -r ../admin_requirements.txt (line 13))\n",
      "  Downloading ipython-8.15.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jedi==0.19.0 (from -r ../admin_requirements.txt (line 14))\n",
      "  Downloading jedi-0.19.0-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jupyter_client==8.3.1 (from -r ../admin_requirements.txt (line 15))\n",
      "  Downloading jupyter_client-8.3.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyter_core==5.3.1 (from -r ../admin_requirements.txt (line 16))\n",
      "  Downloading jupyter_core-5.3.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 17)) (0.1.6)\n",
      "Collecting nest-asyncio==1.5.7 (from -r ../admin_requirements.txt (line 18))\n",
      "  Downloading nest_asyncio-1.5.7-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: packaging==23.1 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 19)) (23.1)\n",
      "Requirement already satisfied: parso==0.8.3 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 20)) (0.8.3)\n",
      "Requirement already satisfied: pexpect==4.8.0 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 21)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 22)) (0.7.5)\n",
      "Collecting platformdirs==3.10.0 (from -r ../admin_requirements.txt (line 23))\n",
      "  Downloading platformdirs-3.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting prompt-toolkit==3.0.39 (from -r ../admin_requirements.txt (line 24))\n",
      "  Downloading prompt_toolkit-3.0.39-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: psutil==5.9.5 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 25)) (5.9.5)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 26)) (0.7.0)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 27)) (0.2.2)\n",
      "Collecting pyaml==23.9.5 (from -r ../admin_requirements.txt (line 28))\n",
      "  Downloading pyaml-23.9.5-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pydantic==2.3.0 (from -r ../admin_requirements.txt (line 29))\n",
      "  Downloading pydantic-2.3.0-py3-none-any.whl.metadata (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.8/148.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic_core==2.6.3 (from -r ../admin_requirements.txt (line 30))\n",
      "  Downloading pydantic_core-2.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting Pygments==2.16.1 (from -r ../admin_requirements.txt (line 31))\n",
      "  Downloading Pygments-2.16.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pymongo==4.5.0 (from -r ../admin_requirements.txt (line 32))\n",
      "  Downloading pymongo-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 33)) (2.8.2)\n",
      "Requirement already satisfied: PyYAML==6.0.1 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 34)) (6.0.1)\n",
      "Requirement already satisfied: pyzmq==25.1.1 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 35)) (25.1.1)\n",
      "Requirement already satisfied: six==1.16.0 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 36)) (1.16.0)\n",
      "Collecting sniffio==1.3.0 (from -r ../admin_requirements.txt (line 37))\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: stack-data==0.6.2 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 38)) (0.6.2)\n",
      "Collecting starlette==0.27.0 (from -r ../admin_requirements.txt (line 39))\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tornado==6.3.3 in /opt/mamba/lib/python3.10/site-packages (from -r ../admin_requirements.txt (line 40)) (6.3.3)\n",
      "Collecting traitlets==5.9.0 (from -r ../admin_requirements.txt (line 41))\n",
      "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing_extensions==4.7.1 (from -r ../admin_requirements.txt (line 42))\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting wcwidth==0.2.6 (from -r ../admin_requirements.txt (line 43))\n",
      "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: exceptiongroup in /opt/mamba/lib/python3.10/site-packages (from anyio==3.7.1->-r ../admin_requirements.txt (line 2)) (1.2.0)\n",
      "Downloading annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asttokens-2.4.0-py2.py3-none-any.whl (27 kB)\n",
      "Downloading debugpy-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.103.1-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipykernel-6.25.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.2/154.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipython-8.15.0-py3-none-any.whl (806 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.6/806.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_client-8.3.1-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_core-5.3.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.7/93.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB)\n",
      "Downloading platformdirs-3.10.0-py3-none-any.whl (17 kB)\n",
      "Downloading prompt_toolkit-3.0.39-py3-none-any.whl (385 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyaml-23.9.5-py3-none-any.whl (22 kB)\n",
      "Downloading pydantic-2.3.0-py3-none-any.whl (374 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Pygments-2.16.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pymongo-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.3/671.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: wcwidth, executing, backcall, typing_extensions, traitlets, sniffio, Pygments, pyaml, prompt-toolkit, platformdirs, nest-asyncio, jedi, dnspython, debugpy, asttokens, annotated-types, pymongo, pydantic_core, jupyter_core, anyio, starlette, pydantic, jupyter_client, ipython, ipykernel, fastapi\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.12\n",
      "    Uninstalling wcwidth-0.2.12:\n",
      "      Successfully uninstalled wcwidth-0.2.12\n",
      "  Attempting uninstall: executing\n",
      "    Found existing installation: executing 2.0.1\n",
      "    Uninstalling executing-2.0.1:\n",
      "      Successfully uninstalled executing-2.0.1\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.13.0\n",
      "    Uninstalling traitlets-5.13.0:\n",
      "      Successfully uninstalled traitlets-5.13.0\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.17.2\n",
      "    Uninstalling Pygments-2.17.2:\n",
      "      Successfully uninstalled Pygments-2.17.2\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.41\n",
      "    Uninstalling prompt-toolkit-3.0.41:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.41\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 4.0.0\n",
      "    Uninstalling platformdirs-4.0.0:\n",
      "      Successfully uninstalled platformdirs-4.0.0\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.8\n",
      "    Uninstalling nest-asyncio-1.5.8:\n",
      "      Successfully uninstalled nest-asyncio-1.5.8\n",
      "  Attempting uninstall: jedi\n",
      "    Found existing installation: jedi 0.19.1\n",
      "    Uninstalling jedi-0.19.1:\n",
      "      Successfully uninstalled jedi-0.19.1\n",
      "  Attempting uninstall: debugpy\n",
      "    Found existing installation: debugpy 1.8.0\n",
      "    Uninstalling debugpy-1.8.0:\n",
      "      Successfully uninstalled debugpy-1.8.0\n",
      "  Attempting uninstall: asttokens\n",
      "    Found existing installation: asttokens 2.4.1\n",
      "    Uninstalling asttokens-2.4.1:\n",
      "      Successfully uninstalled asttokens-2.4.1\n",
      "  Attempting uninstall: jupyter_core\n",
      "    Found existing installation: jupyter_core 5.5.0\n",
      "    Uninstalling jupyter_core-5.5.0:\n",
      "      Successfully uninstalled jupyter_core-5.5.0\n",
      "  Attempting uninstall: jupyter_client\n",
      "    Found existing installation: jupyter_client 8.6.0\n",
      "    Uninstalling jupyter_client-8.6.0:\n",
      "      Successfully uninstalled jupyter_client-8.6.0\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.18.0\n",
      "    Uninstalling ipython-8.18.0:\n",
      "      Successfully uninstalled ipython-8.18.0\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 6.26.0\n",
      "    Uninstalling ipykernel-6.26.0:\n",
      "      Successfully uninstalled ipykernel-6.26.0\n",
      "Successfully installed Pygments-2.16.1 annotated-types-0.5.0 anyio-3.7.1 asttokens-2.4.0 backcall-0.2.0 debugpy-1.7.0 dnspython-2.4.2 executing-1.2.0 fastapi-0.103.1 ipykernel-6.25.2 ipython-8.15.0 jedi-0.19.0 jupyter_client-8.3.1 jupyter_core-5.3.1 nest-asyncio-1.5.7 platformdirs-3.10.0 prompt-toolkit-3.0.39 pyaml-23.9.5 pydantic-2.3.0 pydantic_core-2.6.3 pymongo-4.5.0 sniffio-1.3.0 starlette-0.27.0 traitlets-5.9.0 typing_extensions-4.7.1 wcwidth-0.2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../admin_requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f35fd20-715c-483b-88e4-449c287ba61d",
   "metadata": {},
   "source": [
    "We should now have the required environment to interact with the admin database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d368d6a6-f1fe-4f65-9ce1-38c0b39584d1",
   "metadata": {},
   "source": [
    "### Preparing the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c19b8-303d-4fe8-b515-33ed1099c581",
   "metadata": {},
   "source": [
    "You can visualise all the options offered by the database by running the command `python mongodb_admin.py --help`. We will go through through each of them in the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a749f4b-93cb-460c-bb40-4880df6e51d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: MongoDB administration script for the user database [-h]\n",
      "                                                           {add_user,add_user_with_budget,del_user,add_dataset_to_user,del_dataset_to_user,set_budget_field,set_may_query,show_user,create_users_collection,add_dataset,add_datasets,drop_collection,show_collection}\n",
      "                                                           ...\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "subcommands:\n",
      "  {add_user,add_user_with_budget,del_user,add_dataset_to_user,del_dataset_to_user,set_budget_field,set_may_query,show_user,create_users_collection,add_dataset,add_datasets,drop_collection,show_collection}\n",
      "                        user database administration operations\n",
      "    add_user            add user to users collection\n",
      "    add_user_with_budget\n",
      "                        add user with budget to users collection\n",
      "    del_user            delete user from users collection\n",
      "    add_dataset_to_user\n",
      "                        add dataset with initialized budget values for a user\n",
      "    del_dataset_to_user\n",
      "                        delete dataset for user in users collection\n",
      "    set_budget_field    set budget field to given value for given user and\n",
      "                        dataset\n",
      "    set_may_query       set may query field to given value for given user\n",
      "    show_user           show all metadata of user\n",
      "    create_users_collection\n",
      "                        create users collection from yaml file\n",
      "    add_dataset         set in which database the dataset is stored\n",
      "    add_datasets        create dataset to database type collection\n",
      "    drop_collection     delete collection from database\n",
      "    show_collection     print the users collection\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579cbc3",
   "metadata": {},
   "source": [
    "Let's first make sure the database is empty and in a clean state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18a3681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted collection datasets.\n",
      "Deleted collection metadata.\n",
      "Deleted collection users.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py drop_collection --collection datasets\n",
    "!python mongodb_admin.py drop_collection --collection metadata\n",
    "!python mongodb_admin.py drop_collection --collection users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7edd7d3-20f9-4546-afc8-25661f948d44",
   "metadata": {},
   "source": [
    "### Datasets (add and drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1597b3-767f-470c-a7d7-8fe41dd82da5",
   "metadata": {},
   "source": [
    "We first need to set the dataset meta-information. For each dataset, 2 informations are required:\n",
    "- the type of database in which the dataset is stored\n",
    "- a path to the metadata of the dataset (stored as a yaml file).\n",
    "\n",
    "To later perform query on the dataset, metadata are required. In this secure server the metadata information is expected to be in the same format as [SmartnoiseSQL dictionary format](https://docs.smartnoise.org/sql/metadata.html#dictionary-format), where among other, there is information about all the available columns, their type, bound values (see Smartnoise page for more details). It is also expected to be in a `yaml` file.\n",
    "\n",
    "These information (dataset name, dataset type and metadata path) are stored in the `datasets` collection. Then for each dataset, its metadata is fetched from its `yaml` file and stored in a collection named `metadata`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678fb3f",
   "metadata": {},
   "source": [
    "We then check that there is indeed no data in the dataset and metadata collections yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b7a7fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py show_collection --collection datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d36e03ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py show_collection --collection metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d331ea",
   "metadata": {},
   "source": [
    "We can add **one dataset** with its name, database type and path to medata file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/onyxia/work/sdd-poc-server/server/src'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53f5787d-e721-43d9-85ce-da842f173381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added dataset PENGUIN with database CONSTANT_PATH_DB and metadata from ../data/collections/metadata/penguin_metadata.yaml.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py add_dataset -d PENGUIN -db CONSTANT_PATH_DB -mp ../data/collections/metadata/penguin_metadata.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398f8990",
   "metadata": {},
   "source": [
    "We can now see the dataset and metadata collection with the Iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3005eda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset_name': 'PENGUIN', 'database_type': 'CONSTANT_PATH_DB', 'metadata_path': '../data/collections/metadata/penguin_metadata.yaml'}]\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py show_collection --collection datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7527f3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'PENGUIN': {'': {'Schema': {'Table': {'max_ids': 1, 'row_privacy': True, 'censor_dims': False, 'species': {'type': 'string', 'cardinality': 3, 'categories': ['Adelie', 'Chinstrap', 'Gentoo']}, 'island': {'type': 'string', 'cardinality': 3, 'categories': ['Torgersen', 'Biscoe', 'Dream']}, 'bill_length_mm': {'type': 'float', 'lower': 30.0, 'upper': 65.0}, 'bill_depth_mm': {'type': 'float', 'lower': 13.0, 'upper': 23.0}, 'flipper_length_mm': {'type': 'float', 'lower': 150.0, 'upper': 250.0}, 'body_mass_g': {'type': 'float', 'lower': 2000.0, 'upper': 7000.0}, 'sex': {'type': 'string', 'cardinality': 2, 'categories': ['MALE', 'FEMALE']}}}}, 'engine': 'csv'}}]\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py show_collection --collection metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a2076e",
   "metadata": {},
   "source": [
    "Or a path to a yaml file which contains all these informations to do **multiple datasets** in one command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e42f9cb-3a02-45f5-baee-2e06edda739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning done. \n",
      "Added datasets collection from yaml at ../data/collections/dataset_collection.yaml. \n",
      "Added metadata of IRIS dataset. \n",
      "Added metadata of PENGUIN dataset. \n",
      "Added metadata of TITANIC dataset. \n",
      "Added metadata of FSO_INCOME_SYNTHETIC dataset. \n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py add_datasets --path ../data/collections/dataset_collection.yaml -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument *-c* or *--clean* allows you to clear the current dataset collection before adding your collection.\n",
    "\n",
    "By default, *add_datasets* will only add new dataset found from the collection provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata already exist. User the command -om to overwrite with new values. \n",
      "Metadata already exist. User the command -om to overwrite with new values. \n",
      "Metadata already exist. User the command -om to overwrite with new values. \n",
      "Metadata already exist. User the command -om to overwrite with new values. \n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py add_datasets --path ../data/collections/dataset_collection.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments :\n",
    "\n",
    "*-od* / *--overwrite_datasets* : Overwrite the values for **exisiting datasets** with the values provided in the yaml.\n",
    "\n",
    "*-om* / *--overwrite_metadata* : Overwrite the values for **exisiting metadata** with the values provided in the yaml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing datasets updated with values from yaml at ../data/collections/dataset_collection.yaml. \n",
      "Metadata already exist. User the command -om to overwrite with new values. \n",
      "Metadata already exist. User the command -om to overwrite with new values. \n",
      "Metadata already exist. User the command -om to overwrite with new values. \n",
      "Metadata already exist. User the command -om to overwrite with new values. \n"
     ]
    }
   ],
   "source": [
    "# Add new datasets/metadata, update existing datasets\n",
    "!python mongodb_admin.py add_datasets --path ../data/collections/dataset_collection.yaml -od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata updated with values from yaml for dataset : IRIS. \n",
      "Metadata updated with values from yaml for dataset : PENGUIN. \n",
      "Metadata updated with values from yaml for dataset : TITANIC. \n",
      "Metadata updated with values from yaml for dataset : FSO_INCOME_SYNTHETIC. \n"
     ]
    }
   ],
   "source": [
    "# Add new datasets/metadata, update existing metadata\n",
    "!python mongodb_admin.py add_datasets --path ../data/collections/dataset_collection.yaml -om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing datasets updated with values from yaml at ../data/collections/dataset_collection.yaml. \n",
      "Metadata updated with values from yaml for dataset : IRIS. \n",
      "Metadata updated with values from yaml for dataset : PENGUIN. \n",
      "Metadata updated with values from yaml for dataset : TITANIC. \n",
      "Metadata updated with values from yaml for dataset : FSO_INCOME_SYNTHETIC. \n"
     ]
    }
   ],
   "source": [
    "# Add new datasets/metadata, update existing datasets & metadata\n",
    "!python mongodb_admin.py add_datasets --path ../data/collections/dataset_collection.yaml -od -om"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d686ae",
   "metadata": {},
   "source": [
    "Let's see all the dataset collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "536b5b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset_name': 'IRIS', 'database_type': 'REMOTE_HTTP_DB', 'dataset_url': 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv', 'metadata_path': '../data/collections/metadata/iris_metadata.yaml'}, {'dataset_name': 'PENGUIN', 'database_type': 'REMOTE_HTTP_DB', 'dataset_url': 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv', 'metadata_path': '../data/collections/metadata/penguin_metadata.yaml'}, {'dataset_name': 'TITANIC', 'database_type': 'S3_DB', 's3_bucket': 'example', 's3_key': 'data/titanic.csv', 'endpoint_url': 'https://api-sdd-minio.lab.sspcloud.fr', 'aws_access_key_id': 'admin', 'aws_secret_access_key': 'admin123', 'metadata_path': '../data/collections/metadata/titanic_metadata.yaml'}, {'dataset_name': 'FSO_INCOME_SYNTHETIC', 'database_type': 'LOCAL_DB', 'dataset_path': '../data/datasets/income_synthetic_data.csv', 'metadata_path': '../data/collections/metadata/fso_income_synthetic_metadata.yaml'}]\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py show_collection --collection datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0746b382-8692-445f-9ca9-0d2407a25259",
   "metadata": {},
   "source": [
    "Finally let's have a look at the  stored metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c667dda0-5d0f-48c8-956c-8d8a756b7ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'IRIS': {'': {'Schema': {'Table': {'max_ids': 1, 'petal_length': {'type': 'float', 'lower': 0.5, 'upper': 10.0}, 'petal_width': {'type': 'float', 'lower': 0.05, 'upper': 5.0}, 'row_privacy': True, 'sepal_length': {'type': 'float', 'lower': 2.0, 'upper': 10.0}, 'sepal_width': {'type': 'float', 'lower': 1.0, 'upper': 6.0}, 'species': {'type': 'string', 'cardinality': 3, 'categories': ['setosa', 'versicolor', 'virginica']}}}}, 'engine': 'csv'}}, {'PENGUIN': {'': {'Schema': {'Table': {'max_ids': 1, 'row_privacy': True, 'censor_dims': False, 'species': {'type': 'string', 'cardinality': 3, 'categories': ['Adelie', 'Chinstrap', 'Gentoo']}, 'island': {'type': 'string', 'cardinality': 3, 'categories': ['Torgersen', 'Biscoe', 'Dream']}, 'bill_length_mm': {'type': 'float', 'lower': 30.0, 'upper': 65.0}, 'bill_depth_mm': {'type': 'float', 'lower': 13.0, 'upper': 23.0}, 'flipper_length_mm': {'type': 'float', 'lower': 150.0, 'upper': 250.0}, 'body_mass_g': {'type': 'float', 'lower': 2000.0, 'upper': 7000.0}, 'sex': {'type': 'string', 'cardinality': 2, 'categories': ['MALE', 'FEMALE']}}}}, 'engine': 'csv'}}, {'TITANIC': {'': {'Schema': {'Table': {'max_ids': 1, 'PassengerId': {'type': 'int', 'lower': 1}, 'Pclass': {'type': 'int', 'lower': 1, 'upper': 3}, 'Name': {'type': 'string'}, 'Sex': {'type': 'string', 'categories': ['male', 'female']}, 'Age': {'type': 'int', 'lower': 0.1, 'upper': 100.0}, 'SibSp': {'type': 'int', 'lower': 0}, 'Parch': {'type': 'int', 'lower': 0}, 'Ticket': {'type': 'string'}, 'Fare': {'type': 'float', 'lower': 0.0}, 'Cabin': {'type': 'string'}, 'Embarked': {'type': 'string', 'categories': ['C', 'Q', 'S']}, 'Survived': {'type': 'boolean'}, 'row_privacy': True}}}, 'engine': 'csv'}}, {'FSO_INCOME_SYNTHETIC': {'': {'Schema': {'Table': {'max_ids': 1, 'region': {'type': 'int'}, 'eco_branch': {'type': 'int'}, 'profession': {'type': 'int'}, 'education': {'type': 'int'}, 'age': {'type': 'int'}, 'sex': {'type': 'int'}, 'income': {'type': 'float', 'lower': 1000, 'upper': 100000}}}}, 'engine': 'csv'}}]\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py show_collection --collection metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b85d5",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab18db-4b6d-4663-bde0-b5d9d3d3d2ee",
   "metadata": {},
   "source": [
    "#### Adding users\n",
    "Let's see which users are alreay loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f450145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py show_collection --collection users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ae627",
   "metadata": {},
   "source": [
    "And now let's add few users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f6aa33c-6bd1-4d62-ba06-3533b064340d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added access to user Mrs. Daisy with dataset IRIS, budget epsilon 10.0 and delta 0.001.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py add_user_with_budget --user 'Mrs. Daisy' --dataset 'IRIS' --epsilon 10.0 --delta 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7858f019-8783-4fed-acd8-ff0107d33465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added access to user Mr. Coldheart with dataset PENGUIN, budget epsilon 10.0 and delta 0.001.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py add_user_with_budget --user 'Mr. Coldheart' --dataset 'PENGUIN' --epsilon 10.0 --delta 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "231e7d93-05ba-424a-8329-d96b0bfb4fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added access to user Lord McFreeze with dataset PENGUIN, budget epsilon 10.0 and delta 0.001.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py add_user_with_budget --user 'Lord McFreeze' --dataset 'PENGUIN' --epsilon 10.0 --delta 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b0c274-880c-44f9-9182-6cb162a54c55",
   "metadata": {},
   "source": [
    "Users must all have different names, otherwise you will have an error and nothing will be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6276730e-39c2-47f1-962f-342c1acb7944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/onyxia/work/sdd-poc-server/server/src/mongodb_admin.py\", line 549, in <module>\n",
      "    args.func(args)\n",
      "  File \"/home/onyxia/work/sdd-poc-server/server/src/mongodb_admin.py\", line 47, in add_user_with_budget\n",
      "    raise ValueError(\"Cannot add user because already exists. \")\n",
      "ValueError: Cannot add user because already exists. \n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py add_user_with_budget --user 'Lord McFreeze' --dataset 'IRIS' --epsilon 10.0 --delta 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f81f7e-e086-412f-8467-89b665e5559a",
   "metadata": {},
   "source": [
    "If you want to add another dataset access to an existing user, just use the function `add_dataset_to_user` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82a5f498-aed1-4779-9d73-b2b71dde4ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added access to dataset IRIS to user Lord McFreeze with budget epsilon 5.0 and delta 0.005.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py add_dataset_to_user --user 'Lord McFreeze' --dataset 'IRIS' --epsilon 5.0 --delta 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06170073-49ed-4329-8101-2debdd77eb98",
   "metadata": {},
   "source": [
    "Alternatively, you can create a user without assigned dataset and then add dataset in another command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06839270-36cf-4de7-b93c-d143c4866bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user Madame Frostina.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py add_user --user 'Madame Frostina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e83378fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added access to dataset IRIS to user Madame Frostina with budget epsilon 5.0 and delta 0.005.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py add_dataset_to_user --user 'Madame Frostina' --dataset 'IRIS' --epsilon 5.0 --delta 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "919b2652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added access to dataset PENGUIN to user Madame Frostina with budget epsilon 5.0 and delta 0.005.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py add_dataset_to_user --user 'Madame Frostina' --dataset 'PENGUIN' --epsilon 5.0 --delta 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed2714",
   "metadata": {},
   "source": [
    "And we can also modify existing the total budget of a user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec2cce5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added access to user Dr. Antartica with dataset PENGUIN, budget epsilon 10.0 and delta 0.001.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py add_user_with_budget --user 'Dr. Antartica' --dataset 'PENGUIN' --epsilon 10.0 --delta 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87eecb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set budget of Dr. Antartica for dataset PENGUIN of initial_epsilon to 20.0.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py set_budget_field --user 'Dr. Antartica' --dataset 'PENGUIN' --field initial_epsilon --value 20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeb5dc2-e91e-4440-8df5-3e9506bf4ee1",
   "metadata": {},
   "source": [
    "Let's see the current state of the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b3f61c6-65dc-4b1e-a32e-47cdd2729ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user_name': 'Mrs. Daisy', 'may_query': True, 'datasets_list': [{'dataset_name': 'IRIS', 'initial_epsilon': 10.0, 'initial_delta': 0.001, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}]}, {'user_name': 'Mr. Coldheart', 'may_query': True, 'datasets_list': [{'dataset_name': 'PENGUIN', 'initial_epsilon': 10.0, 'initial_delta': 0.001, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}]}, {'user_name': 'Lord McFreeze', 'may_query': True, 'datasets_list': [{'dataset_name': 'PENGUIN', 'initial_epsilon': 10.0, 'initial_delta': 0.001, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}, {'dataset_name': 'IRIS', 'initial_epsilon': 5.0, 'initial_delta': 0.005, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}]}, {'user_name': 'Madame Frostina', 'may_query': True, 'datasets_list': [{'dataset_name': 'IRIS', 'initial_epsilon': 5.0, 'initial_delta': 0.005, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}, {'dataset_name': 'PENGUIN', 'initial_epsilon': 5.0, 'initial_delta': 0.005, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}]}, {'user_name': 'Dr. Antartica', 'may_query': True, 'datasets_list': [{'dataset_name': 'PENGUIN', 'initial_epsilon': 20.0, 'initial_delta': 0.001, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}]}]\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py show_collection --collection users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ae62f-ff80-4234-8102-4dccec0b284f",
   "metadata": {},
   "source": [
    "Do not hesitate to re-run this command after every other command to ensure that everything runs as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab1f5ba-68bd-4c96-bacd-b81dfa5d6302",
   "metadata": {},
   "source": [
    "#### Removing users\n",
    "You have just heard that the penguin named Coldheart might have malicious intentions and decide to remove his access until an investigation has been carried out. To ensure that he is not allowed to do any more queries, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f341b3d-5a88-4fd9-8c97-cc70145834f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set user Mr. Coldheart may query.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py set_may_query --user 'Mr. Coldheart' --value False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc56586-f9a9-4e88-abed-51ba36a6e4f1",
   "metadata": {},
   "source": [
    "Now, he won't be able to do any query (unless you re-run the query with --value True).\n",
    "\n",
    "A few days have passed and the investigation reveals that he was aiming to do unethical research, you can remove his dataset by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9153d9af-b4be-4496-9f80-d140870f60fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove access to dataset PENGUIN from user Mr. Coldheart.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py del_dataset_to_user --user 'Mr. Coldheart' --dataset 'PENGUIN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d411ae-a211-4997-8984-81281c6275eb",
   "metadata": {},
   "source": [
    "Or delete him completely from the codebase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a54e89eb-1ee1-48ad-9e00-bace8516a3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted user Mr. Coldheart.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py del_user --user 'Mr. Coldheart'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a7c17f-da34-472a-ad7f-3ae73a1beb7b",
   "metadata": {},
   "source": [
    "Let's see the resulting users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "79fa414a-f097-4207-a628-19fa434a1ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user_name': 'Mrs. Daisy', 'may_query': True, 'datasets_list': [{'dataset_name': 'IRIS', 'initial_epsilon': 10.0, 'initial_delta': 0.001, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}]}, {'user_name': 'Lord McFreeze', 'may_query': True, 'datasets_list': [{'dataset_name': 'PENGUIN', 'initial_epsilon': 10.0, 'initial_delta': 0.001, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}, {'dataset_name': 'IRIS', 'initial_epsilon': 5.0, 'initial_delta': 0.005, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}]}, {'user_name': 'Madame Frostina', 'may_query': True, 'datasets_list': [{'dataset_name': 'IRIS', 'initial_epsilon': 5.0, 'initial_delta': 0.005, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}, {'dataset_name': 'PENGUIN', 'initial_epsilon': 5.0, 'initial_delta': 0.005, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}]}, {'user_name': 'Dr. Antartica', 'may_query': True, 'datasets_list': [{'dataset_name': 'PENGUIN', 'initial_epsilon': 20.0, 'initial_delta': 0.001, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}]}]\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py show_collection --collection users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a46a59-70ed-4a26-88cd-6ca8f1d17318",
   "metadata": {},
   "source": [
    "#### Changing the budget\n",
    "You also change your mind about the budget allowed to Lord McFreeze and give him a bit more on the penguin dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0909e6c4-141e-4d57-acd2-bdc0a2d92cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set budget of Lord McFreeze for dataset PENGUIN of initial_epsilon to 15.0.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py set_budget_field --user 'Lord McFreeze' --dataset 'PENGUIN' --field initial_epsilon --value 15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0e110fe-4297-4559-9a95-bc0ebdfa402c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set budget of Lord McFreeze for dataset PENGUIN of initial_delta to 0.005.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py set_budget_field --user 'Lord McFreeze' --dataset 'PENGUIN' --field initial_delta --value 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952d7ed4-ce1d-4a87-9319-6b57968ef20e",
   "metadata": {},
   "source": [
    "Let's check all our changes by looking at the state of the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ab46c5d-1553-4925-bd25-61c9c205dc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user_name': 'Mrs. Daisy', 'may_query': True, 'datasets_list': [{'dataset_name': 'IRIS', 'initial_epsilon': 10.0, 'initial_delta': 0.001, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}]}, {'user_name': 'Lord McFreeze', 'may_query': True, 'datasets_list': [{'dataset_name': 'PENGUIN', 'initial_epsilon': 15.0, 'initial_delta': 0.005, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}, {'dataset_name': 'IRIS', 'initial_epsilon': 5.0, 'initial_delta': 0.005, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}]}, {'user_name': 'Madame Frostina', 'may_query': True, 'datasets_list': [{'dataset_name': 'IRIS', 'initial_epsilon': 5.0, 'initial_delta': 0.005, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}, {'dataset_name': 'PENGUIN', 'initial_epsilon': 5.0, 'initial_delta': 0.005, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}]}, {'user_name': 'Dr. Antartica', 'may_query': True, 'datasets_list': [{'dataset_name': 'PENGUIN', 'initial_epsilon': 20.0, 'initial_delta': 0.001, 'total_spent_epsilon': 0.0, 'total_spent_delta': 0.0}]}]\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py show_collection --collection users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7cfa86",
   "metadata": {},
   "source": [
    "### Finally, everything can actually be loaded directly from a single file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43340fc9",
   "metadata": {},
   "source": [
    "Let's delete the existing user collection first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "597cb0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted collection users.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py drop_collection --collection users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81661298",
   "metadata": {},
   "source": [
    "Is is now empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e1638145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py show_collection --collection users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b3cd2c",
   "metadata": {},
   "source": [
    "We add the data based on a yaml file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87b776f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user data from yaml at ../data/collections/user_collection.yaml.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py create_users_collection --path ../data/collections/user_collection.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, *create_users_collection* will only add new users to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new users added, they already exist in the server\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py create_users_collection --path ../data/collections/user_collection.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to clean the current users collection and replace it, you can use the argument *--clean*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning done. \n",
      "\n",
      "Added user data from yaml at ../data/collections/user_collection.yaml.\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py create_users_collection --path ../data/collections/user_collection.yaml --clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to add new users and update the existing ones in your collection, you can use the argument *--overwrite*. This will make sure to add new users if they do not exist and replace values from existing users with the collection provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing users updated. \n",
      "No new users added, they already exist in the server\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py create_users_collection --path ../data/collections/user_collection.yaml --overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63853e73",
   "metadata": {},
   "source": [
    "And let's see the resulting collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "77866f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user_name': 'Alice', 'may_query': True, 'datasets_list': [{'dataset_name': 'IRIS', 'initial_epsilon': 10, 'initial_delta': 0.0001, 'total_spent_epsilon': 1, 'total_spent_delta': 1e-06}, {'dataset_name': 'PENGUIN', 'initial_epsilon': 5, 'initial_delta': 0.0005, 'total_spent_epsilon': 0.2, 'total_spent_delta': 1e-07}]}, {'user_name': 'Dr. Antartica', 'may_query': True, 'datasets_list': [{'dataset_name': 'PENGUIN', 'initial_epsilon': 45, 'initial_delta': 0.005, 'total_spent_epsilon': 0, 'total_spent_delta': 0}]}, {'user_name': 'Dr. FSO', 'may_query': True, 'datasets_list': [{'dataset_name': 'FSO_INCOME_SYNTHETIC', 'initial_epsilon': 45, 'initial_delta': 0.005, 'total_spent_epsilon': 0, 'total_spent_delta': 0}]}, {'user_name': 'Bob', 'may_query': True, 'datasets_list': [{'dataset_name': 'IRIS', 'initial_epsilon': 10, 'initial_delta': 0.0001, 'total_spent_epsilon': 0, 'total_spent_delta': 0}]}, {'user_name': 'Jack', 'may_query': True, 'datasets_list': [{'dataset_name': 'TITANIC', 'initial_epsilon': 45, 'initial_delta': 0.2, 'total_spent_epsilon': 0, 'total_spent_delta': 0}]}]\n"
     ]
    }
   ],
   "source": [
    "!python mongodb_admin.py show_collection --collection users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archives of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python mongodb_admin show_collection --collection queries_archives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27be3d3-77a2-43d3-9a7f-87c8466293fe",
   "metadata": {},
   "source": [
    "## Stopping the service: Let's not do it right now!\n",
    "\n",
    "To tear down the service, we simply execute the command `helm uninstall sdd-service`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
