{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "363c238d-5925-4b4b-8f68-8ad84ea4705b",
   "metadata": {},
   "source": [
    "# Secure Data Disclosure on Kubernetes: Deployment and Server Administration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1363b-e87e-4d0e-bb3f-9af1a1b72b8d",
   "metadata": {},
   "source": [
    "This notebook showcases how a data owner could set up the service on a kubernetes cluster, add and make their data available to certain user. We will do this in a step by step fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de384c88-559e-4384-a49b-1664ffdd6692",
   "metadata": {},
   "source": [
    "## Deploying the service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba5946",
   "metadata": {},
   "source": [
    "### Building the server image\n",
    "The SDD service comprises a fastapi server and a MongoDB database for keeping state and administration. While the database image is public, the server image must first be built and pushed to a registry.\n",
    "\n",
    "NOTE: For now, the server configuration file is copied and put into the server container. This is of course not practical (and not safe, since the configuration file contains passwords and secrets) and will be updated in future versions. The `config/example_config.yaml` is the one that is copied into the container. One has to change it and rebuild+push the server container in order to change the server configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f688134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker login (=> use personal token from dockerhub, has to be done only once)\n",
    "\n",
    "!cd .. && docker build --target sdd_server_prod -t <your_registry>/sdd_server_prod:latest .\n",
    "!cd .. && docker push <your_registry>/sdd-poc-server:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0034a717",
   "metadata": {},
   "source": [
    "# Start of DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7578d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://sdd-demo.lab.sspcloud.fr/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3237b-6f13-4c52-a9f2-82d94f0b7e66",
   "metadata": {},
   "source": [
    "### Deploying the service Helm chart\n",
    "We use a Helm chart to deploy the service on a Kubernetes cluster. The sdd-server chart is located at `deploy/helm/charts/sdd_server`, let us change our working directory to this location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e249d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../deploy/helm/charts/sdd_server')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11075ea0",
   "metadata": {},
   "source": [
    "The `values.yaml` file contains all the configuration values for the service. We must now update the `image.repository` field to the one we pushed the server container image to. One can also change the url to which the service will be published with `ingress.hosts[0].host` (or disable this feature by setting `ingress.enabled` to `False`).\n",
    "\n",
    "    => Update `values.yaml` file\n",
    "\n",
    "As previously stated, the service is made up of a server and a MongoDB database. Before installing the chart, we must thus first download that dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fe550e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 1 charts\n",
      "Downloading mongodb from repo oci://registry-1.docker.io/bitnamicharts\n",
      "Pulled: registry-1.docker.io/bitnamicharts/mongodb:13.18.1\n",
      "Digest: sha256:f3b2a691537260044746bc4a8898e9ae68e8c29864639737b6da920f99aebe97\n",
      "Deleting outdated charts\n"
     ]
    }
   ],
   "source": [
    "!helm dependency update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2913bce4",
   "metadata": {},
   "source": [
    "Now the chart is ready to be installed, so let the magic happen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5ed0e2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0918 07:49:26.628394  768420 warnings.go:70] annotation \"kubernetes.io/ingress.class\" is deprecated, please use 'spec.ingressClassName' instead\n",
      "NAME: sdd-service\n",
      "LAST DEPLOYED: Mon Sep 18 07:49:24 2023\n",
      "NAMESPACE: user-paulineml\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "NOTES:\n",
      "1. Get the application URL by running these commands:\n",
      "  https://sdd-demo.lab.sspcloud.fr/\n"
     ]
    }
   ],
   "source": [
    "!helm install -f values.yaml sdd-service ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d4837",
   "metadata": {},
   "source": [
    "The installation notes show the url at which the server is exposed. One can have a look at the api docummentation by visiting `<server_url>/docs`\n",
    "\n",
    "One can also check the whether the service started error free by using the `kubectl get all` command as well as inspecting the server logs with `kubectl logs <server-pod-name>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbebd54-8deb-46e6-b811-73ac74028569",
   "metadata": {},
   "source": [
    "## Administering the service by accessing the mongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2ec36f",
   "metadata": {},
   "source": [
    "Let's switch directory again and move to the administration script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ede728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../../../src/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10543e",
   "metadata": {},
   "source": [
    "Let's add a formatting function to have more readable outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0145cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import subprocess\n",
    "\n",
    "def run(command, to_dict=False):\n",
    "    command = f\"python mongodb_admin.py {command}\"\n",
    "    completed_process = subprocess.run(command, shell=True, text=True, capture_output=True)\n",
    "    output = completed_process.stdout\n",
    "    if to_dict:\n",
    "        return literal_eval(output)\n",
    "    else:\n",
    "        output = output.rstrip('\\n').replace(r'\\n', '\\n')\n",
    "        return print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f35fd20-715c-483b-88e4-449c287ba61d",
   "metadata": {},
   "source": [
    "We should now have the required environment to interact with the admin database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d368d6a6-f1fe-4f65-9ce1-38c0b39584d1",
   "metadata": {},
   "source": [
    "### Preparing the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c19b8-303d-4fe8-b515-33ed1099c581",
   "metadata": {},
   "source": [
    "You can visualise all the options offered by the database by running the command `python mongodb_admin.py --help`. We will go through through each of them in the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a749f4b-93cb-460c-bb40-4880df6e51d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: MongoDB administration script for the user database [-h]\n",
      "                                                           {add_user,add_user_with_budget,del_user,add_dataset_to_user,del_dataset_to_user,set_budget_field,set_may_query,show_user,create_users_collection,add_dataset,add_datasets,drop_collection,show_collection}\n",
      "                                                           ...\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "subcommands:\n",
      "  {add_user,add_user_with_budget,del_user,add_dataset_to_user,del_dataset_to_user,set_budget_field,set_may_query,show_user,create_users_collection,add_dataset,add_datasets,drop_collection,show_collection}\n",
      "                        user database administration operations\n",
      "    add_user            add user to users collection\n",
      "    add_user_with_budget\n",
      "                        add user with budget to users collection\n",
      "    del_user            delete user from users collection\n",
      "    add_dataset_to_user\n",
      "                        add dataset with initialized budget values for a user\n",
      "    del_dataset_to_user\n",
      "                        delete dataset for user in users collection\n",
      "    set_budget_field    set budget field to given value for given user and\n",
      "                        dataset\n",
      "    set_may_query       set may query field to given value for given user\n",
      "    show_user           show all metadata of user\n",
      "    create_users_collection\n",
      "                        create users collection from yaml file\n",
      "    add_dataset         set in which database the dataset is stored\n",
      "    add_datasets        create dataset to database type collection\n",
      "    drop_collection     delete collection from database\n",
      "    show_collection     print the users collection\n"
     ]
    }
   ],
   "source": [
    "run(\"--help\") # !python mongodb_admin.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579cbc3",
   "metadata": {},
   "source": [
    "Let's first make sure the database is empty and in a clean state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0863e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted collection datasets.\n"
     ]
    }
   ],
   "source": [
    "run(\"drop_collection --collection datasets\")  # !python mongodb_admin.py drop_collection --collection datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "305f8e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted collection metadata.\n"
     ]
    }
   ],
   "source": [
    "run(\"drop_collection --collection metadata\")  # !python mongodb_admin.py drop_collection --collection metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a3681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted collection users.\n"
     ]
    }
   ],
   "source": [
    "run(\"drop_collection --collection users\")     # !python mongodb_admin.py drop_collection --collection users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7edd7d3-20f9-4546-afc8-25661f948d44",
   "metadata": {},
   "source": [
    "### Datasets (add and drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1597b3-767f-470c-a7d7-8fe41dd82da5",
   "metadata": {},
   "source": [
    "We first need to set the dataset meta-information. For each dataset, 2 informations are required:\n",
    "- the type of database in which the dataset is stored\n",
    "- a path to the metadata of the dataset (stored as a yaml file).\n",
    "\n",
    "To later perform query on the dataset, metadata are required. In this secure server the metadata information is expected to be in the same format as [SmartnoiseSQL dictionary format](https://docs.smartnoise.org/sql/metadata.html#dictionary-format), where among other, there is information about all the available columns, their type, bound values (see Smartnoise page for more details). It is also expected to be in a `yaml` file.\n",
    "\n",
    "These information (dataset name, dataset type and metadata path) are stored in the `datasets` collection. Then for each dataset, its metadata is fetched from its `yaml` file and stored in a collection named `metadata`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678fb3f",
   "metadata": {},
   "source": [
    "We then check that there is indeed no data in the dataset and metadata collections yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b7a7fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "run(\"show_collection --collection datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d36e03ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "run(\"show_collection --collection metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e730b",
   "metadata": {},
   "source": [
    "#### Add one dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d331ea",
   "metadata": {},
   "source": [
    "We can add **one dataset** with its name, database type and path to medata file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53f5787d-e721-43d9-85ce-da842f173381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added dataset PENGUIN with database REMOTE_HTTP_DB and metadata from ../data/collections/metadata/penguin_metadata.yaml.\n"
     ]
    }
   ],
   "source": [
    "run(\"add_dataset -d PENGUIN -db REMOTE_HTTP_DB -mp ../data/collections/metadata/penguin_metadata.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398f8990",
   "metadata": {},
   "source": [
    "We can now see the dataset and metadata collection with the Penguin dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3005eda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset_name': 'PENGUIN',\n",
       "  'database_type': 'REMOTE_HTTP_DB',\n",
       "  'metadata_path': '../data/collections/metadata/penguin_metadata.yaml'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"show_collection --collection datasets\", to_dict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7527f3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'PENGUIN': {'': {'Schema': {'Table': {'max_ids': 1,\n",
       "      'row_privacy': True,\n",
       "      'censor_dims': False,\n",
       "      'species': {'type': 'string',\n",
       "       'cardinality': 3,\n",
       "       'categories': ['Adelie', 'Chinstrap', 'Gentoo']},\n",
       "      'island': {'type': 'string',\n",
       "       'cardinality': 3,\n",
       "       'categories': ['Torgersen', 'Biscoe', 'Dream']},\n",
       "      'bill_length_mm': {'type': 'float', 'lower': 30.0, 'upper': 65.0},\n",
       "      'bill_depth_mm': {'type': 'float', 'lower': 13.0, 'upper': 23.0},\n",
       "      'flipper_length_mm': {'type': 'float', 'lower': 150.0, 'upper': 250.0},\n",
       "      'body_mass_g': {'type': 'float', 'lower': 2000.0, 'upper': 7000.0},\n",
       "      'sex': {'type': 'string',\n",
       "       'cardinality': 2,\n",
       "       'categories': ['MALE', 'FEMALE']}}}},\n",
       "   'engine': 'csv'}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"show_collection --collection metadata\", to_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e57ddf9",
   "metadata": {},
   "source": [
    "#### Add multiple datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a2076e",
   "metadata": {},
   "source": [
    "Or a path to a yaml file which contains all these informations to do **multiple datasets** in one command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e42f9cb-3a02-45f5-baee-2e06edda739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning done. \n",
      "Added datasets collection from yaml at ../data/collections/dataset_collection.yaml. \n",
      "Added metadata of IRIS dataset. \n",
      "Added metadata of PENGUIN dataset. \n",
      "Added metadata of TITANIC dataset. \n",
      "Added metadata of FSO_INCOME_SYNTHETIC dataset. \n"
     ]
    }
   ],
   "source": [
    "run(\"add_datasets --path ../data/collections/dataset_collection.yaml -c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument *-c* or *--clean* allows you to clear the current dataset collection before adding your collection.\n",
    "\n",
    "By default, *add_datasets* will only add new dataset found from the collection provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d686ae",
   "metadata": {},
   "source": [
    "Let's see all the dataset collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "536b5b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset_name': 'IRIS',\n",
       "  'database_type': 'REMOTE_HTTP_DB',\n",
       "  'dataset_url': 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv',\n",
       "  'metadata_path': '../data/collections/metadata/iris_metadata.yaml'},\n",
       " {'dataset_name': 'PENGUIN',\n",
       "  'database_type': 'REMOTE_HTTP_DB',\n",
       "  'dataset_url': 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv',\n",
       "  'metadata_path': '../data/collections/metadata/penguin_metadata.yaml'},\n",
       " {'dataset_name': 'TITANIC',\n",
       "  'database_type': 'S3_DB',\n",
       "  's3_bucket': 'example',\n",
       "  's3_key': 'data/titanic.csv',\n",
       "  'endpoint_url': 'https://api-sdd-minio.lab.sspcloud.fr',\n",
       "  'aws_access_key_id': 'admin',\n",
       "  'aws_secret_access_key': 'admin123',\n",
       "  'metadata_path': '../data/collections/metadata/titanic_metadata.yaml'},\n",
       " {'dataset_name': 'FSO_INCOME_SYNTHETIC',\n",
       "  'database_type': 'LOCAL_DB',\n",
       "  'dataset_path': '../data/datasets/income_synthetic_data.csv',\n",
       "  'metadata_path': '../data/collections/metadata/fso_income_synthetic_metadata.yaml'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"show_collection --collection datasets\", to_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0746b382-8692-445f-9ca9-0d2407a25259",
   "metadata": {},
   "source": [
    "Finally let's have a look at the  stored metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c667dda0-5d0f-48c8-956c-8d8a756b7ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'IRIS': {'': {'Schema': {'Table': {'max_ids': 1,\n",
       "      'petal_length': {'type': 'float', 'lower': 0.5, 'upper': 10.0},\n",
       "      'petal_width': {'type': 'float', 'lower': 0.05, 'upper': 5.0},\n",
       "      'row_privacy': True,\n",
       "      'sepal_length': {'type': 'float', 'lower': 2.0, 'upper': 10.0},\n",
       "      'sepal_width': {'type': 'float', 'lower': 1.0, 'upper': 6.0},\n",
       "      'species': {'type': 'string',\n",
       "       'cardinality': 3,\n",
       "       'categories': ['setosa', 'versicolor', 'virginica']}}}},\n",
       "   'engine': 'csv'}},\n",
       " {'PENGUIN': {'': {'Schema': {'Table': {'max_ids': 1,\n",
       "      'row_privacy': True,\n",
       "      'censor_dims': False,\n",
       "      'species': {'type': 'string',\n",
       "       'cardinality': 3,\n",
       "       'categories': ['Adelie', 'Chinstrap', 'Gentoo']},\n",
       "      'island': {'type': 'string',\n",
       "       'cardinality': 3,\n",
       "       'categories': ['Torgersen', 'Biscoe', 'Dream']},\n",
       "      'bill_length_mm': {'type': 'float', 'lower': 30.0, 'upper': 65.0},\n",
       "      'bill_depth_mm': {'type': 'float', 'lower': 13.0, 'upper': 23.0},\n",
       "      'flipper_length_mm': {'type': 'float', 'lower': 150.0, 'upper': 250.0},\n",
       "      'body_mass_g': {'type': 'float', 'lower': 2000.0, 'upper': 7000.0},\n",
       "      'sex': {'type': 'string',\n",
       "       'cardinality': 2,\n",
       "       'categories': ['MALE', 'FEMALE']}}}},\n",
       "   'engine': 'csv'}},\n",
       " {'TITANIC': {'': {'Schema': {'Table': {'max_ids': 1,\n",
       "      'PassengerId': {'type': 'int', 'lower': 1},\n",
       "      'Pclass': {'type': 'int', 'lower': 1, 'upper': 3},\n",
       "      'Name': {'type': 'string'},\n",
       "      'Sex': {'type': 'string',\n",
       "       'cardinality': 2,\n",
       "       'categories': ['male', 'female']},\n",
       "      'Age': {'type': 'float', 'lower': 0.1, 'upper': 100.0},\n",
       "      'SibSp': {'type': 'int', 'lower': 0},\n",
       "      'Parch': {'type': 'int', 'lower': 0},\n",
       "      'Ticket': {'type': 'string'},\n",
       "      'Fare': {'type': 'float', 'lower': 0.0},\n",
       "      'Cabin': {'type': 'string'},\n",
       "      'Embarked': {'type': 'string',\n",
       "       'cardinality': 3,\n",
       "       'categories': ['C', 'Q', 'S']},\n",
       "      'Survived': {'type': 'boolean'},\n",
       "      'row_privacy': True}}},\n",
       "   'engine': 'csv'}},\n",
       " {'FSO_INCOME_SYNTHETIC': {'': {'Schema': {'Table': {'max_ids': 1,\n",
       "      'region': {'type': 'int'},\n",
       "      'eco_branch': {'type': 'int'},\n",
       "      'profession': {'type': 'int'},\n",
       "      'education': {'type': 'int'},\n",
       "      'age': {'type': 'int'},\n",
       "      'sex': {'type': 'int'},\n",
       "      'income': {'type': 'float', 'lower': 1000, 'upper': 100000}}}},\n",
       "   'engine': 'csv'}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"show_collection --collection metadata\", to_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update multiple datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments :\n",
    "\n",
    "*-c* / *--clean* : clear current dataset collection\n",
    "\n",
    "*-od* / *--overwrite_datasets* : Overwrite the values for **exisiting datasets** with the values provided in the yaml.\n",
    "\n",
    "*-om* / *--overwrite_metadata* : Overwrite the values for **exisiting metadata** with the values provided in the yaml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing datasets updated with values from yaml at ../data/collections/dataset_collection.yaml. \n",
      "Metadata updated with values from yaml for dataset : IRIS. \n",
      "Metadata updated with values from yaml for dataset : PENGUIN. \n",
      "Metadata updated with values from yaml for dataset : TITANIC. \n",
      "Metadata updated with values from yaml for dataset : FSO_INCOME_SYNTHETIC. \n"
     ]
    }
   ],
   "source": [
    "# Add new datasets/metadata, update existing datasets & metadata\n",
    "run(\"add_datasets --path ../data/collections/dataset_collection.yaml -od -om\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b85d5",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab18db-4b6d-4663-bde0-b5d9d3d3d2ee",
   "metadata": {},
   "source": [
    "#### Adding users\n",
    "Let's see which users are alreay loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f450145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "run(\"show_collection --collection users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ae627",
   "metadata": {},
   "source": [
    "And now let's add few users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f6aa33c-6bd1-4d62-ba06-3533b064340d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added access to user Mrs. Daisy with dataset IRIS, budget epsilon 10.0 and delta 0.001.\n"
     ]
    }
   ],
   "source": [
    "run(\"add_user_with_budget --user 'Mrs. Daisy' --dataset 'IRIS' --epsilon 10.0 --delta 0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec2cce5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added access to user Dr. Antartica with dataset PENGUIN, budget epsilon 10.0 and delta 0.002.\n"
     ]
    }
   ],
   "source": [
    "run(\"add_user_with_budget --user 'Dr. Antartica' --dataset 'PENGUIN' --epsilon 10.0 --delta 0.002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "231e7d93-05ba-424a-8329-d96b0bfb4fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added access to user Lord McFreeze with dataset PENGUIN, budget epsilon 10.0 and delta 0.001.\n"
     ]
    }
   ],
   "source": [
    "run(\"add_user_with_budget --user 'Lord McFreeze' --dataset 'PENGUIN' --epsilon 10.0 --delta 0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82a5f498-aed1-4779-9d73-b2b71dde4ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added access to dataset IRIS to user Lord McFreeze with budget epsilon 5.0 and delta 0.005.\n"
     ]
    }
   ],
   "source": [
    "run(\"add_dataset_to_user --user 'Lord McFreeze' --dataset 'IRIS' --epsilon 5.0 --delta 0.005\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed2714",
   "metadata": {},
   "source": [
    "And we can also modify existing the total budget of a user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87eecb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set budget of Dr. Antartica for dataset PENGUIN of initial_epsilon to 20.0.\n"
     ]
    }
   ],
   "source": [
    "run(\"set_budget_field --user 'Dr. Antartica' --dataset 'PENGUIN' --field initial_epsilon --value 20.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeb5dc2-e91e-4440-8df5-3e9506bf4ee1",
   "metadata": {},
   "source": [
    "Let's see the current state of the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b3f61c6-65dc-4b1e-a32e-47cdd2729ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_name': 'Mrs. Daisy',\n",
       "  'may_query': True,\n",
       "  'datasets_list': [{'dataset_name': 'IRIS',\n",
       "    'initial_epsilon': 10.0,\n",
       "    'initial_delta': 0.001,\n",
       "    'total_spent_epsilon': 0.0,\n",
       "    'total_spent_delta': 0.0}]},\n",
       " {'user_name': 'Dr. Antartica',\n",
       "  'may_query': True,\n",
       "  'datasets_list': [{'dataset_name': 'PENGUIN',\n",
       "    'initial_epsilon': 20.0,\n",
       "    'initial_delta': 0.002,\n",
       "    'total_spent_epsilon': 0.0,\n",
       "    'total_spent_delta': 0.0}]},\n",
       " {'user_name': 'Lord McFreeze',\n",
       "  'may_query': True,\n",
       "  'datasets_list': [{'dataset_name': 'PENGUIN',\n",
       "    'initial_epsilon': 10.0,\n",
       "    'initial_delta': 0.001,\n",
       "    'total_spent_epsilon': 0.0,\n",
       "    'total_spent_delta': 0.0},\n",
       "   {'dataset_name': 'IRIS',\n",
       "    'initial_epsilon': 5.0,\n",
       "    'initial_delta': 0.005,\n",
       "    'total_spent_epsilon': 0.0,\n",
       "    'total_spent_delta': 0.0}]}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"show_collection --collection users\", to_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ae62f-ff80-4234-8102-4dccec0b284f",
   "metadata": {},
   "source": [
    "Do not hesitate to re-run this command after every other command to ensure that everything runs as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab1f5ba-68bd-4c96-bacd-b81dfa5d6302",
   "metadata": {},
   "source": [
    "#### Removing users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f341b3d-5a88-4fd9-8c97-cc70145834f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set user Lord McFreeze may query.\n"
     ]
    }
   ],
   "source": [
    "run(\"set_may_query --user 'Lord McFreeze' --value False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc56586-f9a9-4e88-abed-51ba36a6e4f1",
   "metadata": {},
   "source": [
    "Now, he won't be able to do any query (unless you re-run the query with --value True).\n",
    "\n",
    "A few days have passed and the investigation reveals that he was aiming to do unethical research, you can remove his dataset by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9153d9af-b4be-4496-9f80-d140870f60fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove access to dataset PENGUIN from user Lord McFreeze.\n"
     ]
    }
   ],
   "source": [
    "run(\"del_dataset_to_user --user 'Lord McFreeze' --dataset 'PENGUIN'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d411ae-a211-4997-8984-81281c6275eb",
   "metadata": {},
   "source": [
    "Or delete him completely from the codebase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a54e89eb-1ee1-48ad-9e00-bace8516a3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted user Lord McFreeze.\n"
     ]
    }
   ],
   "source": [
    "run(\"del_user --user 'Lord McFreeze'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a7c17f-da34-472a-ad7f-3ae73a1beb7b",
   "metadata": {},
   "source": [
    "Let's see the resulting users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79fa414a-f097-4207-a628-19fa434a1ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_name': 'Mrs. Daisy',\n",
       "  'may_query': True,\n",
       "  'datasets_list': [{'dataset_name': 'IRIS',\n",
       "    'initial_epsilon': 10.0,\n",
       "    'initial_delta': 0.001,\n",
       "    'total_spent_epsilon': 0.0,\n",
       "    'total_spent_delta': 0.0}]},\n",
       " {'user_name': 'Dr. Antartica',\n",
       "  'may_query': True,\n",
       "  'datasets_list': [{'dataset_name': 'PENGUIN',\n",
       "    'initial_epsilon': 20.0,\n",
       "    'initial_delta': 0.002,\n",
       "    'total_spent_epsilon': 0.0,\n",
       "    'total_spent_delta': 0.0}]}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"show_collection --collection users\", to_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7cfa86",
   "metadata": {},
   "source": [
    "### Finally, many users can actually be loaded directly from a single file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43340fc9",
   "metadata": {},
   "source": [
    "Let's delete the existing user collection first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "597cb0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted collection users.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "run(\"drop_collection --collection users\")\n",
    "run(\"show_collection --collection users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b3cd2c",
   "metadata": {},
   "source": [
    "We add the data based on a yaml file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87b776f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning done. \n",
      "\n",
      "Added user data from yaml at ../data/collections/user_collection.yaml.\n"
     ]
    }
   ],
   "source": [
    "run(\"create_users_collection --path ../data/collections/user_collection.yaml -c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can update the users collection with the argument *-o* or *--overwrite*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing users updated. \n",
      "No new users added, they already exist in the server\n"
     ]
    }
   ],
   "source": [
    "run(\"create_users_collection --path ../data/collections/user_collection.yaml --overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63853e73",
   "metadata": {},
   "source": [
    "And let's see the resulting collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77866f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_name': 'Alice',\n",
       "  'may_query': True,\n",
       "  'datasets_list': [{'dataset_name': 'IRIS',\n",
       "    'initial_epsilon': 10,\n",
       "    'initial_delta': 0.0001,\n",
       "    'total_spent_epsilon': 1,\n",
       "    'total_spent_delta': 1e-06},\n",
       "   {'dataset_name': 'PENGUIN',\n",
       "    'initial_epsilon': 5,\n",
       "    'initial_delta': 0.0005,\n",
       "    'total_spent_epsilon': 0.2,\n",
       "    'total_spent_delta': 1e-07}]},\n",
       " {'user_name': 'Dr. Antartica',\n",
       "  'may_query': True,\n",
       "  'datasets_list': [{'dataset_name': 'PENGUIN',\n",
       "    'initial_epsilon': 45,\n",
       "    'initial_delta': 0.005,\n",
       "    'total_spent_epsilon': 0,\n",
       "    'total_spent_delta': 0}]},\n",
       " {'user_name': 'Dr. FSO',\n",
       "  'may_query': True,\n",
       "  'datasets_list': [{'dataset_name': 'FSO_INCOME_SYNTHETIC',\n",
       "    'initial_epsilon': 45,\n",
       "    'initial_delta': 0.005,\n",
       "    'total_spent_epsilon': 0,\n",
       "    'total_spent_delta': 0}]},\n",
       " {'user_name': 'Bob',\n",
       "  'may_query': True,\n",
       "  'datasets_list': [{'dataset_name': 'IRIS',\n",
       "    'initial_epsilon': 10,\n",
       "    'initial_delta': 0.0001,\n",
       "    'total_spent_epsilon': 0,\n",
       "    'total_spent_delta': 0}]},\n",
       " {'user_name': 'Jack',\n",
       "  'may_query': True,\n",
       "  'datasets_list': [{'dataset_name': 'TITANIC',\n",
       "    'initial_epsilon': 45,\n",
       "    'initial_delta': 0.2,\n",
       "    'total_spent_epsilon': 0,\n",
       "    'total_spent_delta': 0}]}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"show_collection --collection users\", to_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed8407",
   "metadata": {},
   "source": [
    "## Archives of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d9a009e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"show_collection --collection queries_archives\", to_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27be3d3-77a2-43d3-9a7f-87c8466293fe",
   "metadata": {},
   "source": [
    "## Stopping the service: Let's not do it right now!\n",
    "\n",
    "To tear down the service, we simply execute the command `helm uninstall sdd-service`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fdbfafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "release \"sdd-service\" uninstalled\n"
     ]
    }
   ],
   "source": [
    "!helm uninstall sdd-service"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
